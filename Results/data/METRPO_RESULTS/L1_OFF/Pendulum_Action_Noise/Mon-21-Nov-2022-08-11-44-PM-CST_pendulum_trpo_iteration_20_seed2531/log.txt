Logging to experiments/pendulum/test-dir-exp/Mon-21-Nov-2022-08-11-44-PM-CST_pendulum_trpo_iteration_20_seed2531
Print configuration .....
{'env_name': 'pendulum', 'random_seeds': [3214, 2431, 2531, 2231], 'save_variables': False, 'model_save_dir': '/tmp/pendulum_models/', 'restore_variables': False, 'start_onpol_iter': 0, 'onpol_iters': 40, 'num_path_random': 25, 'num_path_onpol': 25, 'env_horizon': 200, 'max_train_data': 200000, 'max_val_data': 100000, 'discard_ratio': 0.0, 'dynamics': {'pre_training': {'mode': 'intrinsic_reward', 'itr': 0, 'policy_itr': 20}, 'model': 'nn', 'ensemble': True, 'ensemble_model_count': 5, 'enable_particle_ensemble': True, 'particles': 5, 'obs_var': 1.0, 'intrinsic_reward_coeff': 1.0, 'ita': 1.0, 'mode': 'random', 'val': True, 'n_layers': 4, 'hidden_size': 1000, 'activation': 'relu', 'batch_size': 1000, 'learning_rate': 0.001, 'reg_coeff': 0.0, 'epochs': 200, 'kfac_params': {'learning_rate': 0.1, 'damping': 0.001, 'momentum': 0.9, 'kl_clip': 0.0001, 'cov_ema_decay': 0.99}}, 'policy': {'network_shape': [64, 64], 'init_logstd': 0.0, 'activation': 'tanh', 'reinitialize_every_itr': False}, 'trpo': {'horizon': 200, 'gamma': 0.99, 'step_size': 0.01, 'iterations': 20, 'batch_size': 50000, 'gae': 0.95, 'visualization': False, 'visualize_iterations': [0]}, 'algo': 'trpo'}
Generating random rollouts.
Path 0 | total_timesteps 0.
Path 1 | total_timesteps 200.
Path 2 | total_timesteps 400.
Path 3 | total_timesteps 600.
Path 4 | total_timesteps 800.
Path 5 | total_timesteps 1000.
Path 6 | total_timesteps 1200.
Path 7 | total_timesteps 1400.
Path 8 | total_timesteps 1600.
Path 9 | total_timesteps 1800.
Path 10 | total_timesteps 2000.
Path 11 | total_timesteps 2200.
Path 12 | total_timesteps 2400.
Path 13 | total_timesteps 2600.
Path 14 | total_timesteps 2800.
Path 15 | total_timesteps 3000.
Path 16 | total_timesteps 3200.
Path 17 | total_timesteps 3400.
Path 18 | total_timesteps 3600.
Path 19 | total_timesteps 3800.
Path 20 | total_timesteps 4000.
Path 21 | total_timesteps 4200.
Path 22 | total_timesteps 4400.
Path 23 | total_timesteps 4600.
Path 24 | total_timesteps 4800.
Done generating random rollouts.
Creating normalization for training data.
Done creating normalization for training data.
Particle ensemble enabled? True
An ensemble of 5 dynamics model <class 'model.dynamics.NNDynamicsModel'> initialized
Train dynamics model with intrinsic reward only? False
Pre-training enabled. Using only intrinsic reward.
Pre-training dynamics model for 0 iterations...
Done pre-training dynamics model.
Using external reward only.
itr #0 | 
Fitting dynamics.
Fitting model 0 (0-based) in the ensemble of 5 models
Validation loss = 0.2899424135684967
Validation loss = 0.039333563297986984
Validation loss = 0.014318420551717281
Validation loss = 0.004755319096148014
Validation loss = 0.002174409106373787
Validation loss = 0.00124420877546072
Validation loss = 0.0009064491023309529
Validation loss = 0.0008051760960370302
Validation loss = 0.0007692654035054147
Validation loss = 0.0007003002101555467
Validation loss = 0.00068504927912727
Validation loss = 0.0006397764082066715
Validation loss = 0.0006862558657303452
Validation loss = 0.0006488740327768028
Validation loss = 0.0007520851213485003
Validation loss = 0.0008685262873768806
Fitting model 1 (0-based) in the ensemble of 5 models
Validation loss = 0.27896782755851746
Validation loss = 0.032592736184597015
Validation loss = 0.00827951729297638
Validation loss = 0.0035777308512479067
Validation loss = 0.0016881187912076712
Validation loss = 0.0009560984908603132
Validation loss = 0.0007991833845153451
Validation loss = 0.0006994655122980475
Validation loss = 0.0007182376575656235
Validation loss = 0.0006695101037621498
Validation loss = 0.0006961504113860428
Validation loss = 0.0007331125088967383
Validation loss = 0.0008406075066886842
Validation loss = 0.001217242213897407
Fitting model 2 (0-based) in the ensemble of 5 models
Validation loss = 0.3367316424846649
Validation loss = 0.022103777155280113
Validation loss = 0.008106410503387451
Validation loss = 0.0028388393111526966
Validation loss = 0.0014708824455738068
Validation loss = 0.0009571076952852309
Validation loss = 0.0007756744744256139
Validation loss = 0.0007264207815751433
Validation loss = 0.0007133395411074162
Validation loss = 0.0006584488437511027
Validation loss = 0.003158439416438341
Validation loss = 0.0013301012804731727
Validation loss = 0.0007860916666686535
Validation loss = 0.0006811781204305589
Fitting model 3 (0-based) in the ensemble of 5 models
Validation loss = 0.27110472321510315
Validation loss = 0.03366490453481674
Validation loss = 0.010899652726948261
Validation loss = 0.004742105025798082
Validation loss = 0.0020125035662204027
Validation loss = 0.0011741415364667773
Validation loss = 0.0009308068547397852
Validation loss = 0.0007827003137208521
Validation loss = 0.0007516087498515844
Validation loss = 0.0006862271693535149
Validation loss = 0.0006924564950168133
Validation loss = 0.0006362441345117986
Validation loss = 0.0006505603669211268
Validation loss = 0.0009371665073558688
Validation loss = 0.0009188511176034808
Validation loss = 0.0006428163032978773
Fitting model 4 (0-based) in the ensemble of 5 models
Validation loss = 0.29179245233535767
Validation loss = 0.030885834246873856
Validation loss = 0.008512680418789387
Validation loss = 0.003092267317697406
Validation loss = 0.0014314043801277876
Validation loss = 0.0008913454366847873
Validation loss = 0.0007606618455611169
Validation loss = 0.0007286863401532173
Validation loss = 0.0007381676114164293
Validation loss = 0.00142731296364218
Validation loss = 0.001242480706423521
Validation loss = 0.0060241688042879105
Done fitting dynamics.
Updating randomness.
Done updating randomness.
Training policy using TRPO.
Re-initialize init_std.
Obtaining samples for iteration 0...
Obtaining samples for iteration 1...
Obtaining samples for iteration 2...
Obtaining samples for iteration 3...
Obtaining samples for iteration 4...
Obtaining samples for iteration 5...
Obtaining samples for iteration 6...
Obtaining samples for iteration 7...
Obtaining samples for iteration 8...
Obtaining samples for iteration 9...
Obtaining samples for iteration 10...
Obtaining samples for iteration 11...
Obtaining samples for iteration 12...
Obtaining samples for iteration 13...
Obtaining samples for iteration 14...
Obtaining samples for iteration 15...
Obtaining samples for iteration 16...
Obtaining samples for iteration 17...
Obtaining samples for iteration 18...
Obtaining samples for iteration 19...
Done training policy.
Generating on-policy rollouts.
Path 0 | total_timesteps 0.
Path 1 | total_timesteps 200.
Path 2 | total_timesteps 400.
Path 3 | total_timesteps 600.
Path 4 | total_timesteps 800.
Path 5 | total_timesteps 1000.
Path 6 | total_timesteps 1200.
Path 7 | total_timesteps 1400.
Path 8 | total_timesteps 1600.
Path 9 | total_timesteps 1800.
Path 10 | total_timesteps 2000.
Path 11 | total_timesteps 2200.
Path 12 | total_timesteps 2400.
Path 13 | total_timesteps 2600.
Path 14 | total_timesteps 2800.
Path 15 | total_timesteps 3000.
Path 16 | total_timesteps 3200.
Path 17 | total_timesteps 3400.
Path 18 | total_timesteps 3600.
Path 19 | total_timesteps 3800.
Path 20 | total_timesteps 4000.
Path 21 | total_timesteps 4200.
Path 22 | total_timesteps 4400.
Path 23 | total_timesteps 4600.
Path 24 | total_timesteps 4800.
Done generating on-policy rollouts.
Updating normalization.
Done updating normalization.
----------------------------
| AverageReturn | 167      |
| Iteration     | 0        |
| MaximumReturn | 199      |
| MinimumReturn | 125      |
| TotalSamples  | 6666     |
----------------------------
itr #1 | 
Fitting dynamics.
Fitting model 0 (0-based) in the ensemble of 5 models
Validation loss = 0.013419686816632748
Validation loss = 0.0036787556018680334
Validation loss = 0.00151384889613837
Validation loss = 0.0014106463640928268
Validation loss = 0.0015664086677134037
Validation loss = 0.0013202364789322019
Validation loss = 0.001652332954108715
Validation loss = 0.0013086171820759773
Validation loss = 0.0014116051606833935
Validation loss = 0.001695200684480369
Validation loss = 0.001279362477362156
Validation loss = 0.0012356251245364547
Validation loss = 0.0023434057366102934
Validation loss = 0.001309984247200191
Validation loss = 0.0026555426884442568
Validation loss = 0.0011488035088405013
Validation loss = 0.0012117783771827817
Validation loss = 0.00159536674618721
Validation loss = 0.012341096065938473
Validation loss = 0.0016588539583608508
Fitting model 1 (0-based) in the ensemble of 5 models
Validation loss = 0.01485912874341011
Validation loss = 0.0031543795485049486
Validation loss = 0.0015426744939759374
Validation loss = 0.0013299287529662251
Validation loss = 0.0015524724731221795
Validation loss = 0.004609824623912573
Validation loss = 0.0014075376093387604
Validation loss = 0.0017878372455015779
Fitting model 2 (0-based) in the ensemble of 5 models
Validation loss = 0.011228018440306187
Validation loss = 0.003179504768922925
Validation loss = 0.0020343440119177103
Validation loss = 0.0017394827445968986
Validation loss = 0.0011924542486667633
Validation loss = 0.0012395730009302497
Validation loss = 0.0016994689358398318
Validation loss = 0.001400019391439855
Validation loss = 0.0042489455081522465
Fitting model 3 (0-based) in the ensemble of 5 models
Validation loss = 0.02138657681643963
Validation loss = 0.002832999685779214
Validation loss = 0.0014934759819880128
Validation loss = 0.0012632685247808695
Validation loss = 0.0018209397094324231
Validation loss = 0.001423177309334278
Validation loss = 0.0011977030662819743
Validation loss = 0.0012660768115893006
Validation loss = 0.0017435121117159724
Validation loss = 0.0015938569558784366
Validation loss = 0.001411548932082951
Fitting model 4 (0-based) in the ensemble of 5 models
Validation loss = 0.024011723697185516
Validation loss = 0.0037438676226884127
Validation loss = 0.0015832051867619157
Validation loss = 0.0013833559351041913
Validation loss = 0.0015103061450645328
Validation loss = 0.0018459510756656528
Validation loss = 0.0013721230207011104
Validation loss = 0.001072899904102087
Validation loss = 0.0017428676364943385
Validation loss = 0.0017585312016308308
Validation loss = 0.0015273940516635776
Validation loss = 0.0013387681683525443
Done fitting dynamics.
Updating randomness.
Done updating randomness.
Training policy using TRPO.
Re-initialize init_std.
Obtaining samples for iteration 0...
Obtaining samples for iteration 1...
Obtaining samples for iteration 2...
Obtaining samples for iteration 3...
Obtaining samples for iteration 4...
Obtaining samples for iteration 5...
Obtaining samples for iteration 6...
Obtaining samples for iteration 7...
Obtaining samples for iteration 8...
Obtaining samples for iteration 9...
Obtaining samples for iteration 10...
Obtaining samples for iteration 11...
Obtaining samples for iteration 12...
Obtaining samples for iteration 13...
Obtaining samples for iteration 14...
Obtaining samples for iteration 15...
Obtaining samples for iteration 16...
Obtaining samples for iteration 17...
Obtaining samples for iteration 18...
Obtaining samples for iteration 19...
Done training policy.
Generating on-policy rollouts.
Path 0 | total_timesteps 0.
Path 1 | total_timesteps 200.
Path 2 | total_timesteps 400.
Path 3 | total_timesteps 600.
Path 4 | total_timesteps 800.
Path 5 | total_timesteps 1000.
Path 6 | total_timesteps 1200.
Path 7 | total_timesteps 1400.
Path 8 | total_timesteps 1600.
Path 9 | total_timesteps 1800.
Path 10 | total_timesteps 2000.
Path 11 | total_timesteps 2200.
Path 12 | total_timesteps 2400.
Path 13 | total_timesteps 2600.
Path 14 | total_timesteps 2800.
Path 15 | total_timesteps 3000.
Path 16 | total_timesteps 3200.
Path 17 | total_timesteps 3400.
Path 18 | total_timesteps 3600.
Path 19 | total_timesteps 3800.
Path 20 | total_timesteps 4000.
Path 21 | total_timesteps 4200.
Path 22 | total_timesteps 4400.
Path 23 | total_timesteps 4600.
Path 24 | total_timesteps 4800.
Done generating on-policy rollouts.
Updating normalization.
Done updating normalization.
----------------------------
| AverageReturn | 169      |
| Iteration     | 1        |
| MaximumReturn | 199      |
| MinimumReturn | 120      |
| TotalSamples  | 9999     |
----------------------------
itr #2 | 
Fitting dynamics.
Fitting model 0 (0-based) in the ensemble of 5 models
Validation loss = 0.007695684675127268
Validation loss = 0.0011121536372229457
Validation loss = 0.001518303295597434
Validation loss = 0.0010664775036275387
Validation loss = 0.0011117423418909311
Validation loss = 0.0017380984500050545
Validation loss = 0.0012539171148091555
Validation loss = 0.0011645038612186909
Fitting model 1 (0-based) in the ensemble of 5 models
Validation loss = 0.006498879753053188
Validation loss = 0.0017566774040460587
Validation loss = 0.001595526933670044
Validation loss = 0.001733291195705533
Validation loss = 0.0014616345288231969
Validation loss = 0.0017657282296568155
Validation loss = 0.0011345187667757273
Validation loss = 0.0018007212784141302
Validation loss = 0.0015307089779525995
Validation loss = 0.0020864512771368027
Validation loss = 0.0016535272588953376
Fitting model 2 (0-based) in the ensemble of 5 models
Validation loss = 0.006844927556812763
Validation loss = 0.001361306058242917
Validation loss = 0.0016353331739082932
Validation loss = 0.002505544340237975
Validation loss = 0.001635009073652327
Validation loss = 0.0011156030232086778
Validation loss = 0.0037910949904471636
Validation loss = 0.001117577077820897
Validation loss = 0.001119451830163598
Validation loss = 0.0011114475782960653
Validation loss = 0.00131890713237226
Validation loss = 0.004107954911887646
Validation loss = 0.0010449942201375961
Validation loss = 0.0010250996565446258
Validation loss = 0.004533565137535334
Validation loss = 0.0013822399778291583
Validation loss = 0.0011011381866410375
Validation loss = 0.001058623194694519
Fitting model 3 (0-based) in the ensemble of 5 models
Validation loss = 0.011557744815945625
Validation loss = 0.001127188210375607
Validation loss = 0.0011103206779807806
Validation loss = 0.001292571658268571
Validation loss = 0.0012576256413012743
Validation loss = 0.0008876118808984756
Validation loss = 0.0018471904331818223
Validation loss = 0.0020151734352111816
Validation loss = 0.0014656478306278586
Validation loss = 0.0015834657242521644
Fitting model 4 (0-based) in the ensemble of 5 models
Validation loss = 0.007219498511403799
Validation loss = 0.0017266158247366548
Validation loss = 0.0011952219065278769
Validation loss = 0.0016776397824287415
Validation loss = 0.002043349202722311
Validation loss = 0.0011715723667293787
Validation loss = 0.0017346290405839682
Validation loss = 0.0011919131502509117
Validation loss = 0.004809617064893246
Validation loss = 0.0009905670303851366
Validation loss = 0.001841563149355352
Validation loss = 0.0010177032090723515
Validation loss = 0.0009392889915034175
Validation loss = 0.005722877569496632
Validation loss = 0.0009259362705051899
Validation loss = 0.0019321385771036148
Validation loss = 0.0016758280107751489
Validation loss = 0.0010299801360815763
Validation loss = 0.0019534400198608637
Done fitting dynamics.
Updating randomness.
Done updating randomness.
Training policy using TRPO.
Re-initialize init_std.
Obtaining samples for iteration 0...
Obtaining samples for iteration 1...
Obtaining samples for iteration 2...
Obtaining samples for iteration 3...
Obtaining samples for iteration 4...
Obtaining samples for iteration 5...
Obtaining samples for iteration 6...
Obtaining samples for iteration 7...
Obtaining samples for iteration 8...
Obtaining samples for iteration 9...
Obtaining samples for iteration 10...
Obtaining samples for iteration 11...
Obtaining samples for iteration 12...
Obtaining samples for iteration 13...
Obtaining samples for iteration 14...
Obtaining samples for iteration 15...
Obtaining samples for iteration 16...
Obtaining samples for iteration 17...
Obtaining samples for iteration 18...
Obtaining samples for iteration 19...
Done training policy.
Generating on-policy rollouts.
Path 0 | total_timesteps 0.
Path 1 | total_timesteps 200.
Path 2 | total_timesteps 400.
Path 3 | total_timesteps 600.
Path 4 | total_timesteps 800.
Path 5 | total_timesteps 1000.
Path 6 | total_timesteps 1200.
Path 7 | total_timesteps 1400.
Path 8 | total_timesteps 1600.
Path 9 | total_timesteps 1800.
Path 10 | total_timesteps 2000.
Path 11 | total_timesteps 2200.
Path 12 | total_timesteps 2400.
Path 13 | total_timesteps 2600.
Path 14 | total_timesteps 2800.
Path 15 | total_timesteps 3000.
Path 16 | total_timesteps 3200.
Path 17 | total_timesteps 3400.
Path 18 | total_timesteps 3600.
Path 19 | total_timesteps 3800.
Path 20 | total_timesteps 4000.
Path 21 | total_timesteps 4200.
Path 22 | total_timesteps 4400.
Path 23 | total_timesteps 4600.
Path 24 | total_timesteps 4800.
Done generating on-policy rollouts.
Updating normalization.
Done updating normalization.
----------------------------
| AverageReturn | 176      |
| Iteration     | 2        |
| MaximumReturn | 199      |
| MinimumReturn | 131      |
| TotalSamples  | 13332    |
----------------------------
itr #3 | 
Fitting dynamics.
Fitting model 0 (0-based) in the ensemble of 5 models
Validation loss = 0.002150758169591427
Validation loss = 0.0012177048483863473
Validation loss = 0.0013156733475625515
Validation loss = 0.001784274005331099
Validation loss = 0.0013731213985010982
Validation loss = 0.002237586071714759
Fitting model 1 (0-based) in the ensemble of 5 models
Validation loss = 0.004927278030663729
Validation loss = 0.0010400948813185096
Validation loss = 0.00228109466843307
Validation loss = 0.0010566985001787543
Validation loss = 0.002224241616204381
Validation loss = 0.002024939516559243
Fitting model 2 (0-based) in the ensemble of 5 models
Validation loss = 0.0034818758722394705
Validation loss = 0.0031785136088728905
Validation loss = 0.0009487723582424223
Validation loss = 0.0013410584069788456
Validation loss = 0.0018937151180580258
Validation loss = 0.0036653464194387197
Validation loss = 0.0010155456839129329
Fitting model 3 (0-based) in the ensemble of 5 models
Validation loss = 0.004750646650791168
Validation loss = 0.0009799491381272674
Validation loss = 0.0012208361877128482
Validation loss = 0.002207873621955514
Validation loss = 0.0014814432943239808
Validation loss = 0.0010678943945094943
Fitting model 4 (0-based) in the ensemble of 5 models
Validation loss = 0.004593919962644577
Validation loss = 0.0009244040120393038
Validation loss = 0.001979297026991844
Validation loss = 0.0013547668932005763
Validation loss = 0.0010563384275883436
Validation loss = 0.0014061075635254383
Done fitting dynamics.
Updating randomness.
Done updating randomness.
Training policy using TRPO.
Re-initialize init_std.
Obtaining samples for iteration 0...
Obtaining samples for iteration 1...
Obtaining samples for iteration 2...
Obtaining samples for iteration 3...
Obtaining samples for iteration 4...
Obtaining samples for iteration 5...
Obtaining samples for iteration 6...
Obtaining samples for iteration 7...
Obtaining samples for iteration 8...
Obtaining samples for iteration 9...
Obtaining samples for iteration 10...
Obtaining samples for iteration 11...
Obtaining samples for iteration 12...
Obtaining samples for iteration 13...
Obtaining samples for iteration 14...
Obtaining samples for iteration 15...
Obtaining samples for iteration 16...
Obtaining samples for iteration 17...
Obtaining samples for iteration 18...
Obtaining samples for iteration 19...
Done training policy.
Generating on-policy rollouts.
Path 0 | total_timesteps 0.
Path 1 | total_timesteps 200.
Path 2 | total_timesteps 400.
Path 3 | total_timesteps 600.
Path 4 | total_timesteps 800.
Path 5 | total_timesteps 1000.
Path 6 | total_timesteps 1200.
Path 7 | total_timesteps 1400.
Path 8 | total_timesteps 1600.
Path 9 | total_timesteps 1800.
Path 10 | total_timesteps 2000.
Path 11 | total_timesteps 2200.
Path 12 | total_timesteps 2400.
Path 13 | total_timesteps 2600.
Path 14 | total_timesteps 2800.
Path 15 | total_timesteps 3000.
Path 16 | total_timesteps 3200.
Path 17 | total_timesteps 3400.
Path 18 | total_timesteps 3600.
Path 19 | total_timesteps 3800.
Path 20 | total_timesteps 4000.
Path 21 | total_timesteps 4200.
Path 22 | total_timesteps 4400.
Path 23 | total_timesteps 4600.
Path 24 | total_timesteps 4800.
Done generating on-policy rollouts.
Updating normalization.
Done updating normalization.
----------------------------
| AverageReturn | 168      |
| Iteration     | 3        |
| MaximumReturn | 199      |
| MinimumReturn | 118      |
| TotalSamples  | 16665    |
----------------------------
itr #4 | 
Fitting dynamics.
Fitting model 0 (0-based) in the ensemble of 5 models
Validation loss = 0.0025681941770017147
Validation loss = 0.00112918671220541
Validation loss = 0.0023161612916737795
Validation loss = 0.000997263239696622
Validation loss = 0.0031372234225273132
Validation loss = 0.0010381306055933237
Validation loss = 0.0014470010064542294
Validation loss = 0.001198360463604331
Fitting model 1 (0-based) in the ensemble of 5 models
Validation loss = 0.005602139979600906
Validation loss = 0.001533895032480359
Validation loss = 0.001445647794753313
Validation loss = 0.0017794310115277767
Validation loss = 0.002289330819621682
Validation loss = 0.001196092227473855
Validation loss = 0.0014898886438459158
Validation loss = 0.002217404544353485
Validation loss = 0.0011010831221938133
Validation loss = 0.0009103309130296111
Validation loss = 0.0016686510061845183
Validation loss = 0.0013096171896904707
Validation loss = 0.0013992870226502419
Validation loss = 0.0017853653989732265
Fitting model 2 (0-based) in the ensemble of 5 models
Validation loss = 0.00214491318911314
Validation loss = 0.001637808745726943
Validation loss = 0.001265109982341528
Validation loss = 0.0013747985940426588
Validation loss = 0.001072007929906249
Validation loss = 0.005562835372984409
Validation loss = 0.0012947171926498413
Validation loss = 0.0015842828433960676
Validation loss = 0.0015905059408396482
Fitting model 3 (0-based) in the ensemble of 5 models
Validation loss = 0.008802030235528946
Validation loss = 0.002444077283143997
Validation loss = 0.001128102419897914
Validation loss = 0.0017138724215328693
Validation loss = 0.0008857656503096223
Validation loss = 0.003592914901673794
Validation loss = 0.0010921189095824957
Validation loss = 0.0009253939497284591
Validation loss = 0.003301002783700824
Fitting model 4 (0-based) in the ensemble of 5 models
Validation loss = 0.0035590718034654856
Validation loss = 0.0010966577101498842
Validation loss = 0.0010939538478851318
Validation loss = 0.0027870344929397106
Validation loss = 0.001260841148905456
Validation loss = 0.000794819148723036
Validation loss = 0.0011403285898268223
Validation loss = 0.002311955438926816
Validation loss = 0.0014839485520496964
Validation loss = 0.0015594946453347802
Done fitting dynamics.
Updating randomness.
Done updating randomness.
Training policy using TRPO.
Re-initialize init_std.
Obtaining samples for iteration 0...
Obtaining samples for iteration 1...
Obtaining samples for iteration 2...
Obtaining samples for iteration 3...
Obtaining samples for iteration 4...
Obtaining samples for iteration 5...
Obtaining samples for iteration 6...
Obtaining samples for iteration 7...
Obtaining samples for iteration 8...
Obtaining samples for iteration 9...
Obtaining samples for iteration 10...
Obtaining samples for iteration 11...
Obtaining samples for iteration 12...
Obtaining samples for iteration 13...
Obtaining samples for iteration 14...
Obtaining samples for iteration 15...
Obtaining samples for iteration 16...
Obtaining samples for iteration 17...
Obtaining samples for iteration 18...
Obtaining samples for iteration 19...
Done training policy.
Generating on-policy rollouts.
Path 0 | total_timesteps 0.
Path 1 | total_timesteps 200.
Path 2 | total_timesteps 400.
Path 3 | total_timesteps 600.
Path 4 | total_timesteps 800.
Path 5 | total_timesteps 1000.
Path 6 | total_timesteps 1200.
Path 7 | total_timesteps 1400.
Path 8 | total_timesteps 1600.
Path 9 | total_timesteps 1800.
Path 10 | total_timesteps 2000.
Path 11 | total_timesteps 2200.
Path 12 | total_timesteps 2400.
Path 13 | total_timesteps 2600.
Path 14 | total_timesteps 2800.
Path 15 | total_timesteps 3000.
Path 16 | total_timesteps 3200.
Path 17 | total_timesteps 3400.
Path 18 | total_timesteps 3600.
Path 19 | total_timesteps 3800.
Path 20 | total_timesteps 4000.
Path 21 | total_timesteps 4200.
Path 22 | total_timesteps 4400.
Path 23 | total_timesteps 4600.
Path 24 | total_timesteps 4800.
Done generating on-policy rollouts.
Updating normalization.
Done updating normalization.
----------------------------
| AverageReturn | 171      |
| Iteration     | 4        |
| MaximumReturn | 199      |
| MinimumReturn | 118      |
| TotalSamples  | 19998    |
----------------------------
itr #5 | 
Fitting dynamics.
Fitting model 0 (0-based) in the ensemble of 5 models
Validation loss = 0.0016339992871508002
Validation loss = 0.000956958974711597
Validation loss = 0.0012271376326680183
Validation loss = 0.001217871904373169
Validation loss = 0.0012670450378209352
Validation loss = 0.000890648749191314
Validation loss = 0.002238814253360033
Validation loss = 0.0009723471594043076
Validation loss = 0.0008482242119498551
Validation loss = 0.0032826089300215244
Validation loss = 0.0011115293018519878
Validation loss = 0.0008579208515584469
Validation loss = 0.0013271154602989554
Fitting model 1 (0-based) in the ensemble of 5 models
Validation loss = 0.004614484496414661
Validation loss = 0.0011585552711039782
Validation loss = 0.0012029714416712523
Validation loss = 0.0008919538231566548
Validation loss = 0.0038000226486474276
Validation loss = 0.0012183201033622026
Validation loss = 0.0011373994639143348
Validation loss = 0.004027855582535267
Fitting model 2 (0-based) in the ensemble of 5 models
Validation loss = 0.0017908696318045259
Validation loss = 0.001160100451670587
Validation loss = 0.0008410505251958966
Validation loss = 0.0008531847270205617
Validation loss = 0.0011432650499045849
Validation loss = 0.0028771613724529743
Validation loss = 0.0012487400090321898
Fitting model 3 (0-based) in the ensemble of 5 models
Validation loss = 0.003563903970643878
Validation loss = 0.0016173115000128746
Validation loss = 0.0012275809422135353
Validation loss = 0.002714744536206126
Validation loss = 0.0014690069947391748
Validation loss = 0.0011272316332906485
Validation loss = 0.003980428911745548
Validation loss = 0.0010432300623506308
Validation loss = 0.0013421201147139072
Validation loss = 0.001572123495861888
Validation loss = 0.0009214126621372998
Validation loss = 0.0016688145697116852
Validation loss = 0.0014254834968596697
Validation loss = 0.0008831769227981567
Validation loss = 0.0018901771400123835
Validation loss = 0.003227535169571638
Validation loss = 0.0008303796639665961
Validation loss = 0.00145622156560421
Validation loss = 0.0009974900167435408
Validation loss = 0.0011020796373486519
Validation loss = 0.001381522510200739
Fitting model 4 (0-based) in the ensemble of 5 models
Validation loss = 0.003010303247720003
Validation loss = 0.0011035389034077525
Validation loss = 0.0009239687351509929
Validation loss = 0.0012218153569847345
Validation loss = 0.0013215350918471813
Validation loss = 0.0009319208329543471
Validation loss = 0.002596453297883272
Done fitting dynamics.
Updating randomness.
Done updating randomness.
Training policy using TRPO.
Re-initialize init_std.
Obtaining samples for iteration 0...
Obtaining samples for iteration 1...
Obtaining samples for iteration 2...
Obtaining samples for iteration 3...
Obtaining samples for iteration 4...
Obtaining samples for iteration 5...
Obtaining samples for iteration 6...
Obtaining samples for iteration 7...
Obtaining samples for iteration 8...
Obtaining samples for iteration 9...
Obtaining samples for iteration 10...
Obtaining samples for iteration 11...
Obtaining samples for iteration 12...
Obtaining samples for iteration 13...
Obtaining samples for iteration 14...
Obtaining samples for iteration 15...
Obtaining samples for iteration 16...
Obtaining samples for iteration 17...
Obtaining samples for iteration 18...
Obtaining samples for iteration 19...
Done training policy.
Generating on-policy rollouts.
Path 0 | total_timesteps 0.
Path 1 | total_timesteps 200.
Path 2 | total_timesteps 400.
Path 3 | total_timesteps 600.
Path 4 | total_timesteps 800.
Path 5 | total_timesteps 1000.
Path 6 | total_timesteps 1200.
Path 7 | total_timesteps 1400.
Path 8 | total_timesteps 1600.
Path 9 | total_timesteps 1800.
Path 10 | total_timesteps 2000.
Path 11 | total_timesteps 2200.
Path 12 | total_timesteps 2400.
Path 13 | total_timesteps 2600.
Path 14 | total_timesteps 2800.
Path 15 | total_timesteps 3000.
Path 16 | total_timesteps 3200.
Path 17 | total_timesteps 3400.
Path 18 | total_timesteps 3600.
Path 19 | total_timesteps 3800.
Path 20 | total_timesteps 4000.
Path 21 | total_timesteps 4200.
Path 22 | total_timesteps 4400.
Path 23 | total_timesteps 4600.
Path 24 | total_timesteps 4800.
Done generating on-policy rollouts.
Updating normalization.
Done updating normalization.
----------------------------
| AverageReturn | 168      |
| Iteration     | 5        |
| MaximumReturn | 199      |
| MinimumReturn | 113      |
| TotalSamples  | 23331    |
----------------------------
itr #6 | 
Fitting dynamics.
Fitting model 0 (0-based) in the ensemble of 5 models
Validation loss = 0.0013996153138577938
Validation loss = 0.001512822462245822
Validation loss = 0.001215833704918623
Validation loss = 0.001533500966615975
Validation loss = 0.0007443211507052183
Validation loss = 0.0018139051971957088
Validation loss = 0.0011423657415434718
Validation loss = 0.0015168886166065931
Validation loss = 0.001253511174581945
Fitting model 1 (0-based) in the ensemble of 5 models
Validation loss = 0.002473002765327692
Validation loss = 0.0018711647717282176
Validation loss = 0.0010401029139757156
Validation loss = 0.001208042143844068
Validation loss = 0.0015050680376589298
Validation loss = 0.0033331813756376505
Validation loss = 0.001040030037984252
Validation loss = 0.0011941315606236458
Validation loss = 0.0011719540925696492
Validation loss = 0.0015711105661466718
Validation loss = 0.0008412831812165678
Validation loss = 0.0015443514566868544
Validation loss = 0.000766209268476814
Validation loss = 0.0015383962308987975
Validation loss = 0.0009136564913205802
Validation loss = 0.0008483059937134385
Validation loss = 0.0008919136016629636
Fitting model 2 (0-based) in the ensemble of 5 models
Validation loss = 0.00190154614392668
Validation loss = 0.0015576581936329603
Validation loss = 0.0018953728722408414
Validation loss = 0.0007949285791255534
Validation loss = 0.0008734068251214921
Validation loss = 0.001055553206242621
Validation loss = 0.0008906109142117202
Validation loss = 0.0015648126136511564
Fitting model 3 (0-based) in the ensemble of 5 models
Validation loss = 0.0027316566556692123
Validation loss = 0.0011358929332345724
Validation loss = 0.0020787531975656748
Validation loss = 0.001661975751630962
Validation loss = 0.0010953258024528623
Validation loss = 0.001388563890941441
Validation loss = 0.0008184624603018165
Validation loss = 0.0012714873300865293
Validation loss = 0.0016692123608663678
Validation loss = 0.0007334999390877783
Validation loss = 0.0009743768605403602
Validation loss = 0.001291173743084073
Validation loss = 0.0016021300107240677
Validation loss = 0.0011098656104877591
Fitting model 4 (0-based) in the ensemble of 5 models
Validation loss = 0.0025377380661666393
Validation loss = 0.0011996646644547582
Validation loss = 0.0016282200813293457
Validation loss = 0.001058611087501049
Validation loss = 0.00187597272451967
Validation loss = 0.0010561193339526653
Validation loss = 0.001460316707380116
Validation loss = 0.0017047678120434284
Validation loss = 0.0011272587580606341
Validation loss = 0.0011014477349817753
Done fitting dynamics.
Updating randomness.
Done updating randomness.
Training policy using TRPO.
Re-initialize init_std.
Obtaining samples for iteration 0...
Obtaining samples for iteration 1...
Obtaining samples for iteration 2...
Obtaining samples for iteration 3...
Obtaining samples for iteration 4...
Obtaining samples for iteration 5...
Obtaining samples for iteration 6...
Obtaining samples for iteration 7...
Obtaining samples for iteration 8...
Obtaining samples for iteration 9...
Obtaining samples for iteration 10...
Obtaining samples for iteration 11...
Obtaining samples for iteration 12...
Obtaining samples for iteration 13...
Obtaining samples for iteration 14...
Obtaining samples for iteration 15...
Obtaining samples for iteration 16...
Obtaining samples for iteration 17...
Obtaining samples for iteration 18...
Obtaining samples for iteration 19...
Done training policy.
Generating on-policy rollouts.
Path 0 | total_timesteps 0.
Path 1 | total_timesteps 200.
Path 2 | total_timesteps 400.
Path 3 | total_timesteps 600.
Path 4 | total_timesteps 800.
Path 5 | total_timesteps 1000.
Path 6 | total_timesteps 1200.
Path 7 | total_timesteps 1400.
Path 8 | total_timesteps 1600.
Path 9 | total_timesteps 1800.
Path 10 | total_timesteps 2000.
Path 11 | total_timesteps 2200.
Path 12 | total_timesteps 2400.
Path 13 | total_timesteps 2600.
Path 14 | total_timesteps 2800.
Path 15 | total_timesteps 3000.
Path 16 | total_timesteps 3200.
Path 17 | total_timesteps 3400.
Path 18 | total_timesteps 3600.
Path 19 | total_timesteps 3800.
Path 20 | total_timesteps 4000.
Path 21 | total_timesteps 4200.
Path 22 | total_timesteps 4400.
Path 23 | total_timesteps 4600.
Path 24 | total_timesteps 4800.
Done generating on-policy rollouts.
Updating normalization.
Done updating normalization.
----------------------------
| AverageReturn | 172      |
| Iteration     | 6        |
| MaximumReturn | 199      |
| MinimumReturn | 131      |
| TotalSamples  | 26664    |
----------------------------
itr #7 | 
Fitting dynamics.
Fitting model 0 (0-based) in the ensemble of 5 models
Validation loss = 0.0012703572865575552
Validation loss = 0.0017134430818259716
Validation loss = 0.0010876489104703069
Validation loss = 0.0008999499841593206
Validation loss = 0.001165413879789412
Validation loss = 0.0009547175141051412
Validation loss = 0.001259403768926859
Validation loss = 0.0021457686088979244
Fitting model 1 (0-based) in the ensemble of 5 models
Validation loss = 0.0015437921974807978
Validation loss = 0.0018330668099224567
Validation loss = 0.0008123474544845521
Validation loss = 0.001164951827377081
Validation loss = 0.0015003635780885816
Validation loss = 0.0013055559247732162
Validation loss = 0.0007466008537448943
Validation loss = 0.0013362605823203921
Validation loss = 0.0008382968953810632
Validation loss = 0.0009960306342691183
Validation loss = 0.001313018728978932
Fitting model 2 (0-based) in the ensemble of 5 models
Validation loss = 0.0014949979959055781
Validation loss = 0.0012950899545103312
Validation loss = 0.0013895799638703465
Validation loss = 0.0009368060855194926
Validation loss = 0.001272569759748876
Validation loss = 0.0017142248107120395
Validation loss = 0.000866212067194283
Validation loss = 0.001122013432905078
Validation loss = 0.0008658422157168388
Validation loss = 0.0012100082822144032
Validation loss = 0.0008302266942337155
Validation loss = 0.0013599465601146221
Validation loss = 0.0010200110264122486
Validation loss = 0.0016473454888910055
Validation loss = 0.001020696246996522
Fitting model 3 (0-based) in the ensemble of 5 models
Validation loss = 0.0036065916065126657
Validation loss = 0.0010828302474692464
Validation loss = 0.0010344833135604858
Validation loss = 0.0009081161115318537
Validation loss = 0.001267319661565125
Validation loss = 0.001637918408960104
Validation loss = 0.0012847301550209522
Validation loss = 0.0007406662916764617
Validation loss = 0.000871839583851397
Validation loss = 0.0011880897218361497
Validation loss = 0.0007262370781973004
Validation loss = 0.0011306344531476498
Validation loss = 0.0007575429626740515
Validation loss = 0.0009873663075268269
Validation loss = 0.0009423914016224444
Fitting model 4 (0-based) in the ensemble of 5 models
Validation loss = 0.0011434953194111586
Validation loss = 0.000944815983530134
Validation loss = 0.0010772128589451313
Validation loss = 0.0014831610023975372
Validation loss = 0.001252944115549326
Validation loss = 0.0008821609662845731
Validation loss = 0.0008502177661284804
Validation loss = 0.0010845318902283907
Validation loss = 0.0018263941165059805
Validation loss = 0.0009843367151916027
Validation loss = 0.0008697457378730178
Done fitting dynamics.
Updating randomness.
Done updating randomness.
Training policy using TRPO.
Re-initialize init_std.
Obtaining samples for iteration 0...
Obtaining samples for iteration 1...
Obtaining samples for iteration 2...
Obtaining samples for iteration 3...
Obtaining samples for iteration 4...
Obtaining samples for iteration 5...
Obtaining samples for iteration 6...
Obtaining samples for iteration 7...
Obtaining samples for iteration 8...
Obtaining samples for iteration 9...
Obtaining samples for iteration 10...
Obtaining samples for iteration 11...
Obtaining samples for iteration 12...
Obtaining samples for iteration 13...
Obtaining samples for iteration 14...
Obtaining samples for iteration 15...
Obtaining samples for iteration 16...
Obtaining samples for iteration 17...
Obtaining samples for iteration 18...
Obtaining samples for iteration 19...
Done training policy.
Generating on-policy rollouts.
Path 0 | total_timesteps 0.
Path 1 | total_timesteps 200.
Path 2 | total_timesteps 400.
Path 3 | total_timesteps 600.
Path 4 | total_timesteps 800.
Path 5 | total_timesteps 1000.
Path 6 | total_timesteps 1200.
Path 7 | total_timesteps 1400.
Path 8 | total_timesteps 1600.
Path 9 | total_timesteps 1800.
Path 10 | total_timesteps 2000.
Path 11 | total_timesteps 2200.
Path 12 | total_timesteps 2400.
Path 13 | total_timesteps 2600.
Path 14 | total_timesteps 2800.
Path 15 | total_timesteps 3000.
Path 16 | total_timesteps 3200.
Path 17 | total_timesteps 3400.
Path 18 | total_timesteps 3600.
Path 19 | total_timesteps 3800.
Path 20 | total_timesteps 4000.
Path 21 | total_timesteps 4200.
Path 22 | total_timesteps 4400.
Path 23 | total_timesteps 4600.
Path 24 | total_timesteps 4800.
Done generating on-policy rollouts.
Updating normalization.
Done updating normalization.
----------------------------
| AverageReturn | 177      |
| Iteration     | 7        |
| MaximumReturn | 199      |
| MinimumReturn | 126      |
| TotalSamples  | 29997    |
----------------------------
itr #8 | 
Fitting dynamics.
Fitting model 0 (0-based) in the ensemble of 5 models
Validation loss = 0.0010532201267778873
Validation loss = 0.0008774041780270636
Validation loss = 0.0012427099281921983
Validation loss = 0.0008122875588014722
Validation loss = 0.0008559476118534803
Validation loss = 0.0010405138600617647
Validation loss = 0.0009376511443406343
Validation loss = 0.0010933236917480826
Fitting model 1 (0-based) in the ensemble of 5 models
Validation loss = 0.0025753933005034924
Validation loss = 0.0008995154057629406
Validation loss = 0.0016773673705756664
Validation loss = 0.0008848618599586189
Validation loss = 0.0011471235193312168
Validation loss = 0.0007475406164303422
Validation loss = 0.0007404225179925561
Validation loss = 0.0008320760680362582
Validation loss = 0.0009266814449802041
Validation loss = 0.0010733596282079816
Validation loss = 0.0009853902738541365
Fitting model 2 (0-based) in the ensemble of 5 models
Validation loss = 0.0007963564130477607
Validation loss = 0.0012098439037799835
Validation loss = 0.0010262419236823916
Validation loss = 0.0007494529709219933
Validation loss = 0.0010728442575782537
Validation loss = 0.0010456540621817112
Validation loss = 0.0023467191495001316
Validation loss = 0.0013234722428023815
Fitting model 3 (0-based) in the ensemble of 5 models
Validation loss = 0.0014807017287239432
Validation loss = 0.0010801500175148249
Validation loss = 0.0007872601272538304
Validation loss = 0.0010144360130652785
Validation loss = 0.0007841862388886511
Validation loss = 0.000829467608127743
Validation loss = 0.001416840241290629
Validation loss = 0.0007177164079621434
Validation loss = 0.000811232952401042
Validation loss = 0.001182348933070898
Validation loss = 0.0008507495513185859
Validation loss = 0.0007364107295870781
Fitting model 4 (0-based) in the ensemble of 5 models
Validation loss = 0.0009808930335566401
Validation loss = 0.0020835036411881447
Validation loss = 0.0010513333836570382
Validation loss = 0.0009096547728404403
Validation loss = 0.001060245092958212
Validation loss = 0.0009034479735419154
Validation loss = 0.001179548678919673
Validation loss = 0.0007028077961876988
Validation loss = 0.0008229694794863462
Validation loss = 0.0010845405049622059
Validation loss = 0.0008535481174476445
Validation loss = 0.0011259806342422962
Done fitting dynamics.
Updating randomness.
Done updating randomness.
Training policy using TRPO.
Re-initialize init_std.
Obtaining samples for iteration 0...
Obtaining samples for iteration 1...
Obtaining samples for iteration 2...
Obtaining samples for iteration 3...
Obtaining samples for iteration 4...
Obtaining samples for iteration 5...
Obtaining samples for iteration 6...
Obtaining samples for iteration 7...
Obtaining samples for iteration 8...
Obtaining samples for iteration 9...
Obtaining samples for iteration 10...
Obtaining samples for iteration 11...
Obtaining samples for iteration 12...
Obtaining samples for iteration 13...
Obtaining samples for iteration 14...
Obtaining samples for iteration 15...
Obtaining samples for iteration 16...
Obtaining samples for iteration 17...
Obtaining samples for iteration 18...
Obtaining samples for iteration 19...
Done training policy.
Generating on-policy rollouts.
Path 0 | total_timesteps 0.
Path 1 | total_timesteps 200.
Path 2 | total_timesteps 400.
Path 3 | total_timesteps 600.
Path 4 | total_timesteps 800.
Path 5 | total_timesteps 1000.
Path 6 | total_timesteps 1200.
Path 7 | total_timesteps 1400.
Path 8 | total_timesteps 1600.
Path 9 | total_timesteps 1800.
Path 10 | total_timesteps 2000.
Path 11 | total_timesteps 2200.
Path 12 | total_timesteps 2400.
Path 13 | total_timesteps 2600.
Path 14 | total_timesteps 2800.
Path 15 | total_timesteps 3000.
Path 16 | total_timesteps 3200.
Path 17 | total_timesteps 3400.
Path 18 | total_timesteps 3600.
Path 19 | total_timesteps 3800.
Path 20 | total_timesteps 4000.
Path 21 | total_timesteps 4200.
Path 22 | total_timesteps 4400.
Path 23 | total_timesteps 4600.
Path 24 | total_timesteps 4800.
Done generating on-policy rollouts.
Updating normalization.
Done updating normalization.
----------------------------
| AverageReturn | 170      |
| Iteration     | 8        |
| MaximumReturn | 199      |
| MinimumReturn | 121      |
| TotalSamples  | 33330    |
----------------------------
itr #9 | 
Fitting dynamics.
Fitting model 0 (0-based) in the ensemble of 5 models
Validation loss = 0.001106491545215249
Validation loss = 0.0012167186941951513
Validation loss = 0.0008221479365602136
Validation loss = 0.0007758359424769878
Validation loss = 0.0013075459282845259
Validation loss = 0.0008050956530496478
Validation loss = 0.0009203507797792554
Validation loss = 0.001051005208864808
Fitting model 1 (0-based) in the ensemble of 5 models
Validation loss = 0.0010956182377412915
Validation loss = 0.0008525443263351917
Validation loss = 0.0009543769992887974
Validation loss = 0.0007932864828035235
Validation loss = 0.0016441227635368705
Validation loss = 0.0007738613057881594
Validation loss = 0.001001024735160172
Validation loss = 0.0006680128863081336
Validation loss = 0.0011609371285885572
Validation loss = 0.0018641750793904066
Validation loss = 0.0007433326682075858
Validation loss = 0.0007830879185348749
Fitting model 2 (0-based) in the ensemble of 5 models
Validation loss = 0.0011088962201029062
Validation loss = 0.0007385030039586127
Validation loss = 0.0007380520110018551
Validation loss = 0.0007648379541933537
Validation loss = 0.0008390417788177729
Validation loss = 0.0012401824351400137
Validation loss = 0.0009918509749695659
Fitting model 3 (0-based) in the ensemble of 5 models
Validation loss = 0.0009670887957327068
Validation loss = 0.001185889821499586
Validation loss = 0.0007434336002916098
Validation loss = 0.0008317564497701824
Validation loss = 0.000985351507551968
Validation loss = 0.0009805858135223389
Validation loss = 0.0013370232190936804
Fitting model 4 (0-based) in the ensemble of 5 models
Validation loss = 0.0009181896457448602
Validation loss = 0.0008426147978752851
Validation loss = 0.0012057882267981768
Validation loss = 0.0008687223307788372
Validation loss = 0.0008559625712223351
Validation loss = 0.0009781245607882738
Done fitting dynamics.
Updating randomness.
Done updating randomness.
Training policy using TRPO.
Re-initialize init_std.
Obtaining samples for iteration 0...
Obtaining samples for iteration 1...
Obtaining samples for iteration 2...
Obtaining samples for iteration 3...
Obtaining samples for iteration 4...
Obtaining samples for iteration 5...
Obtaining samples for iteration 6...
Obtaining samples for iteration 7...
Obtaining samples for iteration 8...
Obtaining samples for iteration 9...
Obtaining samples for iteration 10...
Obtaining samples for iteration 11...
Obtaining samples for iteration 12...
Obtaining samples for iteration 13...
Obtaining samples for iteration 14...
Obtaining samples for iteration 15...
Obtaining samples for iteration 16...
Obtaining samples for iteration 17...
Obtaining samples for iteration 18...
Obtaining samples for iteration 19...
Done training policy.
Generating on-policy rollouts.
Path 0 | total_timesteps 0.
Path 1 | total_timesteps 200.
Path 2 | total_timesteps 400.
Path 3 | total_timesteps 600.
Path 4 | total_timesteps 800.
Path 5 | total_timesteps 1000.
Path 6 | total_timesteps 1200.
Path 7 | total_timesteps 1400.
Path 8 | total_timesteps 1600.
Path 9 | total_timesteps 1800.
Path 10 | total_timesteps 2000.
Path 11 | total_timesteps 2200.
Path 12 | total_timesteps 2400.
Path 13 | total_timesteps 2600.
Path 14 | total_timesteps 2800.
Path 15 | total_timesteps 3000.
Path 16 | total_timesteps 3200.
Path 17 | total_timesteps 3400.
Path 18 | total_timesteps 3600.
Path 19 | total_timesteps 3800.
Path 20 | total_timesteps 4000.
Path 21 | total_timesteps 4200.
Path 22 | total_timesteps 4400.
Path 23 | total_timesteps 4600.
Path 24 | total_timesteps 4800.
Done generating on-policy rollouts.
Updating normalization.
Done updating normalization.
----------------------------
| AverageReturn | 173      |
| Iteration     | 9        |
| MaximumReturn | 199      |
| MinimumReturn | 128      |
| TotalSamples  | 36663    |
----------------------------
itr #10 | 
Fitting dynamics.
Fitting model 0 (0-based) in the ensemble of 5 models
Validation loss = 0.0017716182628646493
Validation loss = 0.0007428711396642029
Validation loss = 0.0008621351444162428
Validation loss = 0.0014574389206245542
Validation loss = 0.0011364161036908627
Validation loss = 0.000979872071184218
Fitting model 1 (0-based) in the ensemble of 5 models
Validation loss = 0.0018495118711143732
Validation loss = 0.000718124967534095
Validation loss = 0.0008303280337713659
Validation loss = 0.000818502448964864
Validation loss = 0.0007040898781269789
Validation loss = 0.000912651710677892
Validation loss = 0.000667906308081001
Validation loss = 0.0008824205724522471
Validation loss = 0.0009414905216544867
Validation loss = 0.001434445846825838
Validation loss = 0.0009138284949585795
Fitting model 2 (0-based) in the ensemble of 5 models
Validation loss = 0.000859552004840225
Validation loss = 0.0009039097931236029
Validation loss = 0.0007952283485792577
Validation loss = 0.0008074476500041783
Validation loss = 0.0007693609222769737
Validation loss = 0.001063516247086227
Validation loss = 0.0013572514289990067
Validation loss = 0.0006860740832053125
Validation loss = 0.0010299705900251865
Validation loss = 0.0010517650516703725
Validation loss = 0.0007137813372537494
Validation loss = 0.0007744927424937487
Fitting model 3 (0-based) in the ensemble of 5 models
Validation loss = 0.0007854034192860126
Validation loss = 0.0006811782950535417
Validation loss = 0.001297895098105073
Validation loss = 0.000741900410503149
Validation loss = 0.0007694393862038851
Validation loss = 0.0007624612771905959
Fitting model 4 (0-based) in the ensemble of 5 models
Validation loss = 0.0010555577464401722
Validation loss = 0.0009064686018973589
Validation loss = 0.0007372917607426643
Validation loss = 0.0010450631380081177
Validation loss = 0.0008993207011371851
Validation loss = 0.0010846664663404226
Validation loss = 0.0009327064035460353
Done fitting dynamics.
Updating randomness.
Done updating randomness.
Training policy using TRPO.
Re-initialize init_std.
Obtaining samples for iteration 0...
Obtaining samples for iteration 1...
Obtaining samples for iteration 2...
Obtaining samples for iteration 3...
Obtaining samples for iteration 4...
Obtaining samples for iteration 5...
Obtaining samples for iteration 6...
Obtaining samples for iteration 7...
Obtaining samples for iteration 8...
Obtaining samples for iteration 9...
Obtaining samples for iteration 10...
Obtaining samples for iteration 11...
Obtaining samples for iteration 12...
Obtaining samples for iteration 13...
Obtaining samples for iteration 14...
Obtaining samples for iteration 15...
Obtaining samples for iteration 16...
Obtaining samples for iteration 17...
Obtaining samples for iteration 18...
Obtaining samples for iteration 19...
Done training policy.
Generating on-policy rollouts.
Path 0 | total_timesteps 0.
Path 1 | total_timesteps 200.
Path 2 | total_timesteps 400.
Path 3 | total_timesteps 600.
Path 4 | total_timesteps 800.
Path 5 | total_timesteps 1000.
Path 6 | total_timesteps 1200.
Path 7 | total_timesteps 1400.
Path 8 | total_timesteps 1600.
Path 9 | total_timesteps 1800.
Path 10 | total_timesteps 2000.
Path 11 | total_timesteps 2200.
Path 12 | total_timesteps 2400.
Path 13 | total_timesteps 2600.
Path 14 | total_timesteps 2800.
Path 15 | total_timesteps 3000.
Path 16 | total_timesteps 3200.
Path 17 | total_timesteps 3400.
Path 18 | total_timesteps 3600.
Path 19 | total_timesteps 3800.
Path 20 | total_timesteps 4000.
Path 21 | total_timesteps 4200.
Path 22 | total_timesteps 4400.
Path 23 | total_timesteps 4600.
Path 24 | total_timesteps 4800.
Done generating on-policy rollouts.
Updating normalization.
Done updating normalization.
----------------------------
| AverageReturn | 178      |
| Iteration     | 10       |
| MaximumReturn | 199      |
| MinimumReturn | 124      |
| TotalSamples  | 39996    |
----------------------------
itr #11 | 
Fitting dynamics.
Fitting model 0 (0-based) in the ensemble of 5 models
Validation loss = 0.0012864116579294205
Validation loss = 0.0010952886659651995
Validation loss = 0.0007521038060076535
Validation loss = 0.001098093343898654
Validation loss = 0.001073756837286055
Validation loss = 0.0014294440625235438
Validation loss = 0.0010126186534762383
Fitting model 1 (0-based) in the ensemble of 5 models
Validation loss = 0.0012865005992352962
Validation loss = 0.000832168385386467
Validation loss = 0.0006424172897823155
Validation loss = 0.0008334800368174911
Validation loss = 0.0009791248012334108
Validation loss = 0.0009984525386244059
Validation loss = 0.0010356985731050372
Fitting model 2 (0-based) in the ensemble of 5 models
Validation loss = 0.0007946089026518166
Validation loss = 0.00102884357329458
Validation loss = 0.0009547179797664285
Validation loss = 0.00084781862096861
Validation loss = 0.0007196525693871081
Validation loss = 0.000822313129901886
Validation loss = 0.0009213777957484126
Validation loss = 0.0010414388962090015
Validation loss = 0.0007292887312360108
Fitting model 3 (0-based) in the ensemble of 5 models
Validation loss = 0.0009235778707079589
Validation loss = 0.0008457609219476581
Validation loss = 0.0009269947186112404
Validation loss = 0.0008906596340239048
Validation loss = 0.0007074327440932393
Validation loss = 0.0007194216595962644
Validation loss = 0.0011048793094232678
Validation loss = 0.0007190395263023674
Validation loss = 0.001121281529776752
Fitting model 4 (0-based) in the ensemble of 5 models
Validation loss = 0.0009666996775195003
Validation loss = 0.0008605809998698533
Validation loss = 0.0018604292999953032
Validation loss = 0.0009289933368563652
Validation loss = 0.0010144648840650916
Validation loss = 0.0008547225734218955
Validation loss = 0.0008393687312491238
Validation loss = 0.0011084569850936532
Validation loss = 0.0009049989166669548
Validation loss = 0.000804784067440778
Validation loss = 0.0007803511689417064
Validation loss = 0.0007122280658222735
Validation loss = 0.0006959060556255281
Validation loss = 0.0006588742835447192
Validation loss = 0.0007434826693497598
Validation loss = 0.0015515706036239862
Validation loss = 0.0006676819175481796
Validation loss = 0.0006446632323786616
Validation loss = 0.0009270423324778676
Validation loss = 0.0006126898224465549
Validation loss = 0.0007390849059447646
Validation loss = 0.0009226128458976746
Validation loss = 0.0008237370057031512
Validation loss = 0.00096809834940359
Done fitting dynamics.
Updating randomness.
Done updating randomness.
Training policy using TRPO.
Re-initialize init_std.
Obtaining samples for iteration 0...
Obtaining samples for iteration 1...
Obtaining samples for iteration 2...
Obtaining samples for iteration 3...
Obtaining samples for iteration 4...
Obtaining samples for iteration 5...
Obtaining samples for iteration 6...
Obtaining samples for iteration 7...
Obtaining samples for iteration 8...
Obtaining samples for iteration 9...
Obtaining samples for iteration 10...
Obtaining samples for iteration 11...
Obtaining samples for iteration 12...
Obtaining samples for iteration 13...
Obtaining samples for iteration 14...
Obtaining samples for iteration 15...
Obtaining samples for iteration 16...
Obtaining samples for iteration 17...
Obtaining samples for iteration 18...
Obtaining samples for iteration 19...
Done training policy.
Generating on-policy rollouts.
Path 0 | total_timesteps 0.
Path 1 | total_timesteps 200.
Path 2 | total_timesteps 400.
Path 3 | total_timesteps 600.
Path 4 | total_timesteps 800.
Path 5 | total_timesteps 1000.
Path 6 | total_timesteps 1200.
Path 7 | total_timesteps 1400.
Path 8 | total_timesteps 1600.
Path 9 | total_timesteps 1800.
Path 10 | total_timesteps 2000.
Path 11 | total_timesteps 2200.
Path 12 | total_timesteps 2400.
Path 13 | total_timesteps 2600.
Path 14 | total_timesteps 2800.
Path 15 | total_timesteps 3000.
Path 16 | total_timesteps 3200.
Path 17 | total_timesteps 3400.
Path 18 | total_timesteps 3600.
Path 19 | total_timesteps 3800.
Path 20 | total_timesteps 4000.
Path 21 | total_timesteps 4200.
Path 22 | total_timesteps 4400.
Path 23 | total_timesteps 4600.
Path 24 | total_timesteps 4800.
Done generating on-policy rollouts.
Updating normalization.
Done updating normalization.
----------------------------
| AverageReturn | 169      |
| Iteration     | 11       |
| MaximumReturn | 199      |
| MinimumReturn | 121      |
| TotalSamples  | 43329    |
----------------------------
itr #12 | 
Fitting dynamics.
Fitting model 0 (0-based) in the ensemble of 5 models
Validation loss = 0.0011712962295860052
Validation loss = 0.001051897881552577
Validation loss = 0.0009621825884096324
Validation loss = 0.0009103403426706791
Validation loss = 0.0012810943881049752
Validation loss = 0.0007557926001027226
Validation loss = 0.0006815270753577352
Validation loss = 0.0007743510068394244
Validation loss = 0.0011108352337032557
Validation loss = 0.0011172755621373653
Validation loss = 0.0007322249584831297
Fitting model 1 (0-based) in the ensemble of 5 models
Validation loss = 0.0006126798689365387
Validation loss = 0.0006195452297106385
Validation loss = 0.0008080118568614125
Validation loss = 0.0011640430893748999
Validation loss = 0.0009605808299966156
Fitting model 2 (0-based) in the ensemble of 5 models
Validation loss = 0.0008262902265414596
Validation loss = 0.001042881398461759
Validation loss = 0.0011412566527724266
Validation loss = 0.0010542342206463218
Validation loss = 0.0007385860080830753
Validation loss = 0.0007430316181853414
Validation loss = 0.0008654504781588912
Validation loss = 0.0014946942683309317
Validation loss = 0.0007543546962551773
Fitting model 3 (0-based) in the ensemble of 5 models
Validation loss = 0.0008094622171483934
Validation loss = 0.0006455626571550965
Validation loss = 0.0006639097700826824
Validation loss = 0.0007523567182943225
Validation loss = 0.0008183294557966292
Validation loss = 0.0007956300978548825
Fitting model 4 (0-based) in the ensemble of 5 models
Validation loss = 0.0008101607672870159
Validation loss = 0.000640844227746129
Validation loss = 0.0008545023738406599
Validation loss = 0.0009632562869228423
Validation loss = 0.0008205990307033062
Validation loss = 0.0008757621981203556
Done fitting dynamics.
Updating randomness.
Done updating randomness.
Training policy using TRPO.
Re-initialize init_std.
Obtaining samples for iteration 0...
Obtaining samples for iteration 1...
Obtaining samples for iteration 2...
Obtaining samples for iteration 3...
Obtaining samples for iteration 4...
Obtaining samples for iteration 5...
Obtaining samples for iteration 6...
Obtaining samples for iteration 7...
Obtaining samples for iteration 8...
Obtaining samples for iteration 9...
Obtaining samples for iteration 10...
Obtaining samples for iteration 11...
Obtaining samples for iteration 12...
Obtaining samples for iteration 13...
Obtaining samples for iteration 14...
Obtaining samples for iteration 15...
Obtaining samples for iteration 16...
Obtaining samples for iteration 17...
Obtaining samples for iteration 18...
Obtaining samples for iteration 19...
Done training policy.
Generating on-policy rollouts.
Path 0 | total_timesteps 0.
Path 1 | total_timesteps 200.
Path 2 | total_timesteps 400.
Path 3 | total_timesteps 600.
Path 4 | total_timesteps 800.
Path 5 | total_timesteps 1000.
Path 6 | total_timesteps 1200.
Path 7 | total_timesteps 1400.
Path 8 | total_timesteps 1600.
Path 9 | total_timesteps 1800.
Path 10 | total_timesteps 2000.
Path 11 | total_timesteps 2200.
Path 12 | total_timesteps 2400.
Path 13 | total_timesteps 2600.
Path 14 | total_timesteps 2800.
Path 15 | total_timesteps 3000.
Path 16 | total_timesteps 3200.
Path 17 | total_timesteps 3400.
Path 18 | total_timesteps 3600.
Path 19 | total_timesteps 3800.
Path 20 | total_timesteps 4000.
Path 21 | total_timesteps 4200.
Path 22 | total_timesteps 4400.
Path 23 | total_timesteps 4600.
Path 24 | total_timesteps 4800.
Done generating on-policy rollouts.
Updating normalization.
Done updating normalization.
----------------------------
| AverageReturn | 170      |
| Iteration     | 12       |
| MaximumReturn | 198      |
| MinimumReturn | 126      |
| TotalSamples  | 46662    |
----------------------------
itr #13 | 
Fitting dynamics.
Fitting model 0 (0-based) in the ensemble of 5 models
Validation loss = 0.0009207624825648963
Validation loss = 0.0008063287823460996
Validation loss = 0.0008162935264408588
Validation loss = 0.0007876016898080707
Validation loss = 0.0007026971434243023
Validation loss = 0.0007332060486078262
Validation loss = 0.0006778897950425744
Validation loss = 0.0007340866723097861
Validation loss = 0.0007087147096171975
Validation loss = 0.0008068862953223288
Validation loss = 0.0007560394005849957
Fitting model 1 (0-based) in the ensemble of 5 models
Validation loss = 0.0007293903036043048
Validation loss = 0.0006246428238227963
Validation loss = 0.0008575384272262454
Validation loss = 0.0006331549375317991
Validation loss = 0.0008982833242043853
Validation loss = 0.0007329208310693502
Fitting model 2 (0-based) in the ensemble of 5 models
Validation loss = 0.0008447344298474491
Validation loss = 0.0006240104557946324
Validation loss = 0.000855470250826329
Validation loss = 0.0007834671996533871
Validation loss = 0.0006337016238830984
Validation loss = 0.0008749152766540647
Fitting model 3 (0-based) in the ensemble of 5 models
Validation loss = 0.0007582761463709176
Validation loss = 0.000982261379249394
Validation loss = 0.0009951478568837047
Validation loss = 0.0007075964822433889
Validation loss = 0.0008988456684164703
Validation loss = 0.0007151210447773337
Validation loss = 0.0007839122554287314
Validation loss = 0.0007337130955420434
Fitting model 4 (0-based) in the ensemble of 5 models
Validation loss = 0.0006423898157663643
Validation loss = 0.0006907677161507308
Validation loss = 0.0006060419254936278
Validation loss = 0.000664012914057821
Validation loss = 0.0009961728937923908
Validation loss = 0.0013460774207487702
Validation loss = 0.0006450274959206581
Done fitting dynamics.
Updating randomness.
Done updating randomness.
Training policy using TRPO.
Re-initialize init_std.
Obtaining samples for iteration 0...
Obtaining samples for iteration 1...
Obtaining samples for iteration 2...
Obtaining samples for iteration 3...
Obtaining samples for iteration 4...
Obtaining samples for iteration 5...
Obtaining samples for iteration 6...
Obtaining samples for iteration 7...
Obtaining samples for iteration 8...
Obtaining samples for iteration 9...
Obtaining samples for iteration 10...
Obtaining samples for iteration 11...
Obtaining samples for iteration 12...
Obtaining samples for iteration 13...
Obtaining samples for iteration 14...
Obtaining samples for iteration 15...
Obtaining samples for iteration 16...
Obtaining samples for iteration 17...
Obtaining samples for iteration 18...
Obtaining samples for iteration 19...
Done training policy.
Generating on-policy rollouts.
Path 0 | total_timesteps 0.
Path 1 | total_timesteps 200.
Path 2 | total_timesteps 400.
Path 3 | total_timesteps 600.
Path 4 | total_timesteps 800.
Path 5 | total_timesteps 1000.
Path 6 | total_timesteps 1200.
Path 7 | total_timesteps 1400.
Path 8 | total_timesteps 1600.
Path 9 | total_timesteps 1800.
Path 10 | total_timesteps 2000.
Path 11 | total_timesteps 2200.
Path 12 | total_timesteps 2400.
Path 13 | total_timesteps 2600.
Path 14 | total_timesteps 2800.
Path 15 | total_timesteps 3000.
Path 16 | total_timesteps 3200.
Path 17 | total_timesteps 3400.
Path 18 | total_timesteps 3600.
Path 19 | total_timesteps 3800.
Path 20 | total_timesteps 4000.
Path 21 | total_timesteps 4200.
Path 22 | total_timesteps 4400.
Path 23 | total_timesteps 4600.
Path 24 | total_timesteps 4800.
Done generating on-policy rollouts.
Updating normalization.
Done updating normalization.
----------------------------
| AverageReturn | 162      |
| Iteration     | 13       |
| MaximumReturn | 199      |
| MinimumReturn | 124      |
| TotalSamples  | 49995    |
----------------------------
itr #14 | 
Fitting dynamics.
Fitting model 0 (0-based) in the ensemble of 5 models
Validation loss = 0.000638165045529604
Validation loss = 0.0007749242940917611
Validation loss = 0.0006920346640981734
Validation loss = 0.0010631510522216558
Validation loss = 0.0006769828032702208
Fitting model 1 (0-based) in the ensemble of 5 models
Validation loss = 0.0008559149573557079
Validation loss = 0.0006229827995412052
Validation loss = 0.0010563078103587031
Validation loss = 0.0007478235638700426
Validation loss = 0.0010828714584931731
Validation loss = 0.0010542012751102448
Fitting model 2 (0-based) in the ensemble of 5 models
Validation loss = 0.0009305524872615933
Validation loss = 0.0008307807729579508
Validation loss = 0.0006398261175490916
Validation loss = 0.0007340867887251079
Validation loss = 0.0006066433852538466
Validation loss = 0.0006866389303468168
Validation loss = 0.0006589434924535453
Validation loss = 0.0006529323873110116
Validation loss = 0.000794731080532074
Fitting model 3 (0-based) in the ensemble of 5 models
Validation loss = 0.0007247213507071137
Validation loss = 0.0007656179368495941
Validation loss = 0.0007424583891406655
Validation loss = 0.0008659510058350861
Validation loss = 0.0006468751234933734
Validation loss = 0.0009140314650721848
Validation loss = 0.0006823137518949807
Validation loss = 0.0007026481907814741
Validation loss = 0.0008681318140588701
Fitting model 4 (0-based) in the ensemble of 5 models
Validation loss = 0.0007383986376225948
Validation loss = 0.0008637556456960738
Validation loss = 0.0006354448851197958
Validation loss = 0.0007380701717920601
Validation loss = 0.0006965015782043338
Validation loss = 0.000728088547475636
Validation loss = 0.0007245379965752363
Done fitting dynamics.
Updating randomness.
Done updating randomness.
Training policy using TRPO.
Re-initialize init_std.
Obtaining samples for iteration 0...
Obtaining samples for iteration 1...
Obtaining samples for iteration 2...
Obtaining samples for iteration 3...
Obtaining samples for iteration 4...
Obtaining samples for iteration 5...
Obtaining samples for iteration 6...
Obtaining samples for iteration 7...
Obtaining samples for iteration 8...
Obtaining samples for iteration 9...
Obtaining samples for iteration 10...
Obtaining samples for iteration 11...
Obtaining samples for iteration 12...
Obtaining samples for iteration 13...
Obtaining samples for iteration 14...
Obtaining samples for iteration 15...
Obtaining samples for iteration 16...
Obtaining samples for iteration 17...
Obtaining samples for iteration 18...
Obtaining samples for iteration 19...
Done training policy.
Generating on-policy rollouts.
Path 0 | total_timesteps 0.
Path 1 | total_timesteps 200.
Path 2 | total_timesteps 400.
Path 3 | total_timesteps 600.
Path 4 | total_timesteps 800.
Path 5 | total_timesteps 1000.
Path 6 | total_timesteps 1200.
Path 7 | total_timesteps 1400.
Path 8 | total_timesteps 1600.
Path 9 | total_timesteps 1800.
Path 10 | total_timesteps 2000.
Path 11 | total_timesteps 2200.
Path 12 | total_timesteps 2400.
Path 13 | total_timesteps 2600.
Path 14 | total_timesteps 2800.
Path 15 | total_timesteps 3000.
Path 16 | total_timesteps 3200.
Path 17 | total_timesteps 3400.
Path 18 | total_timesteps 3600.
Path 19 | total_timesteps 3800.
Path 20 | total_timesteps 4000.
Path 21 | total_timesteps 4200.
Path 22 | total_timesteps 4400.
Path 23 | total_timesteps 4600.
Path 24 | total_timesteps 4800.
Done generating on-policy rollouts.
Updating normalization.
Done updating normalization.
----------------------------
| AverageReturn | 175      |
| Iteration     | 14       |
| MaximumReturn | 199      |
| MinimumReturn | 137      |
| TotalSamples  | 53328    |
----------------------------
itr #15 | 
Fitting dynamics.
Fitting model 0 (0-based) in the ensemble of 5 models
Validation loss = 0.0007312462548725307
Validation loss = 0.0006806199089623988
Validation loss = 0.0007192995981313288
Validation loss = 0.0006307413568720222
Validation loss = 0.0007021740893833339
Validation loss = 0.0008451531757600605
Validation loss = 0.0010518616763874888
Validation loss = 0.0006139941979199648
Validation loss = 0.0008475764188915491
Validation loss = 0.0007790270610712469
Validation loss = 0.0007537233177572489
Validation loss = 0.0007714732200838625
Fitting model 1 (0-based) in the ensemble of 5 models
Validation loss = 0.000735354726202786
Validation loss = 0.0006192184519022703
Validation loss = 0.0008311994024552405
Validation loss = 0.0007478035404346883
Validation loss = 0.0007281398866325617
Validation loss = 0.0006942687905393541
Fitting model 2 (0-based) in the ensemble of 5 models
Validation loss = 0.0008476984803564847
Validation loss = 0.0006843892624601722
Validation loss = 0.0007047365070320666
Validation loss = 0.0006611809367313981
Validation loss = 0.0009408447076566517
Validation loss = 0.000671684043481946
Validation loss = 0.0007651317864656448
Validation loss = 0.000722335244063288
Fitting model 3 (0-based) in the ensemble of 5 models
Validation loss = 0.0007818206795491278
Validation loss = 0.0008456342620775104
Validation loss = 0.0011679499875754118
Validation loss = 0.0007676821551285684
Validation loss = 0.0009053993271663785
Validation loss = 0.0007962810341268778
Validation loss = 0.0008626198978163302
Validation loss = 0.0008063629502430558
Fitting model 4 (0-based) in the ensemble of 5 models
Validation loss = 0.0007296539261005819
Validation loss = 0.001775180920958519
Validation loss = 0.0007274943054653704
Validation loss = 0.0007040174677968025
Validation loss = 0.0008730808040127158
Validation loss = 0.001064737094566226
Validation loss = 0.0007773297256790102
Validation loss = 0.0006783043500036001
Validation loss = 0.0009914989350363612
Validation loss = 0.0006041103624738753
Validation loss = 0.0008282719645649195
Validation loss = 0.0007481568609364331
Validation loss = 0.0008430338348262012
Validation loss = 0.0006196418544277549
Done fitting dynamics.
Updating randomness.
Done updating randomness.
Training policy using TRPO.
Re-initialize init_std.
Obtaining samples for iteration 0...
Obtaining samples for iteration 1...
Obtaining samples for iteration 2...
Obtaining samples for iteration 3...
Obtaining samples for iteration 4...
Obtaining samples for iteration 5...
Obtaining samples for iteration 6...
Obtaining samples for iteration 7...
Obtaining samples for iteration 8...
Obtaining samples for iteration 9...
Obtaining samples for iteration 10...
Obtaining samples for iteration 11...
Obtaining samples for iteration 12...
Obtaining samples for iteration 13...
Obtaining samples for iteration 14...
Obtaining samples for iteration 15...
Obtaining samples for iteration 16...
Obtaining samples for iteration 17...
Obtaining samples for iteration 18...
Obtaining samples for iteration 19...
Done training policy.
Generating on-policy rollouts.
Path 0 | total_timesteps 0.
Path 1 | total_timesteps 200.
Path 2 | total_timesteps 400.
Path 3 | total_timesteps 600.
Path 4 | total_timesteps 800.
Path 5 | total_timesteps 1000.
Path 6 | total_timesteps 1200.
Path 7 | total_timesteps 1400.
Path 8 | total_timesteps 1600.
Path 9 | total_timesteps 1800.
Path 10 | total_timesteps 2000.
Path 11 | total_timesteps 2200.
Path 12 | total_timesteps 2400.
Path 13 | total_timesteps 2600.
Path 14 | total_timesteps 2800.
Path 15 | total_timesteps 3000.
Path 16 | total_timesteps 3200.
Path 17 | total_timesteps 3400.
Path 18 | total_timesteps 3600.
Path 19 | total_timesteps 3800.
Path 20 | total_timesteps 4000.
Path 21 | total_timesteps 4200.
Path 22 | total_timesteps 4400.
Path 23 | total_timesteps 4600.
Path 24 | total_timesteps 4800.
Done generating on-policy rollouts.
Updating normalization.
Done updating normalization.
----------------------------
| AverageReturn | 176      |
| Iteration     | 15       |
| MaximumReturn | 199      |
| MinimumReturn | 132      |
| TotalSamples  | 56661    |
----------------------------
itr #16 | 
Fitting dynamics.
Fitting model 0 (0-based) in the ensemble of 5 models
Validation loss = 0.0009234949829988182
Validation loss = 0.0007117259665392339
Validation loss = 0.0007599391392432153
Validation loss = 0.0006799781112931669
Validation loss = 0.0009367305901832879
Validation loss = 0.0006558616296388209
Validation loss = 0.0006263238028623164
Validation loss = 0.0008761365315876901
Validation loss = 0.0007102837553247809
Validation loss = 0.0006804876611568034
Validation loss = 0.0007690757629461586
Fitting model 1 (0-based) in the ensemble of 5 models
Validation loss = 0.0007477215840481222
Validation loss = 0.0006921021267771721
Validation loss = 0.0008945059380494058
Validation loss = 0.0006411420763470232
Validation loss = 0.0006916834972798824
Validation loss = 0.0006491632084362209
Validation loss = 0.0008445320418104529
Validation loss = 0.0006770145846530795
Fitting model 2 (0-based) in the ensemble of 5 models
Validation loss = 0.0007384304772131145
Validation loss = 0.0006194175221025944
Validation loss = 0.0009319147211499512
Validation loss = 0.0006565105286426842
Validation loss = 0.0005915158544667065
Validation loss = 0.0006621723296120763
Validation loss = 0.0006448773783631623
Validation loss = 0.0005793189047835767
Validation loss = 0.0006587763200514019
Validation loss = 0.0005867354921065271
Validation loss = 0.0006182529614306986
Validation loss = 0.0006647140835411847
Fitting model 3 (0-based) in the ensemble of 5 models
Validation loss = 0.0013201602268964052
Validation loss = 0.0006402257713489234
Validation loss = 0.0005739894695580006
Validation loss = 0.0007582967518828809
Validation loss = 0.0006927917129360139
Validation loss = 0.0006286163115873933
Validation loss = 0.0011631827801465988
Fitting model 4 (0-based) in the ensemble of 5 models
Validation loss = 0.0006593558937311172
Validation loss = 0.0007283827872015536
Validation loss = 0.0006479374133050442
Validation loss = 0.0006248172139748931
Validation loss = 0.000678679789416492
Validation loss = 0.0008911217446438968
Validation loss = 0.0006725772982463241
Validation loss = 0.0006589304539375007
Done fitting dynamics.
Updating randomness.
Done updating randomness.
Training policy using TRPO.
Re-initialize init_std.
Obtaining samples for iteration 0...
Obtaining samples for iteration 1...
Obtaining samples for iteration 2...
Obtaining samples for iteration 3...
Obtaining samples for iteration 4...
Obtaining samples for iteration 5...
Obtaining samples for iteration 6...
Obtaining samples for iteration 7...
Obtaining samples for iteration 8...
Obtaining samples for iteration 9...
Obtaining samples for iteration 10...
Obtaining samples for iteration 11...
Obtaining samples for iteration 12...
Obtaining samples for iteration 13...
Obtaining samples for iteration 14...
Obtaining samples for iteration 15...
Obtaining samples for iteration 16...
Obtaining samples for iteration 17...
Obtaining samples for iteration 18...
Obtaining samples for iteration 19...
Done training policy.
Generating on-policy rollouts.
Path 0 | total_timesteps 0.
Path 1 | total_timesteps 200.
Path 2 | total_timesteps 400.
Path 3 | total_timesteps 600.
Path 4 | total_timesteps 800.
Path 5 | total_timesteps 1000.
Path 6 | total_timesteps 1200.
Path 7 | total_timesteps 1400.
Path 8 | total_timesteps 1600.
Path 9 | total_timesteps 1800.
Path 10 | total_timesteps 2000.
Path 11 | total_timesteps 2200.
Path 12 | total_timesteps 2400.
Path 13 | total_timesteps 2600.
Path 14 | total_timesteps 2800.
Path 15 | total_timesteps 3000.
Path 16 | total_timesteps 3200.
Path 17 | total_timesteps 3400.
Path 18 | total_timesteps 3600.
Path 19 | total_timesteps 3800.
Path 20 | total_timesteps 4000.
Path 21 | total_timesteps 4200.
Path 22 | total_timesteps 4400.
Path 23 | total_timesteps 4600.
Path 24 | total_timesteps 4800.
Done generating on-policy rollouts.
Updating normalization.
Done updating normalization.
----------------------------
| AverageReturn | 177      |
| Iteration     | 16       |
| MaximumReturn | 199      |
| MinimumReturn | 127      |
| TotalSamples  | 59994    |
----------------------------
itr #17 | 
Fitting dynamics.
Fitting model 0 (0-based) in the ensemble of 5 models
Validation loss = 0.0010404561180621386
Validation loss = 0.0006444745813496411
Validation loss = 0.0006937418365851045
Validation loss = 0.0007882985519245267
Validation loss = 0.0006321560358628631
Validation loss = 0.0007013401482254267
Validation loss = 0.000631950912065804
Validation loss = 0.0006125323125161231
Validation loss = 0.0006123482598923147
Validation loss = 0.0016986943082883954
Validation loss = 0.0007100091897882521
Validation loss = 0.0006712781614623964
Validation loss = 0.0007385235512629151
Fitting model 1 (0-based) in the ensemble of 5 models
Validation loss = 0.0005891819018870592
Validation loss = 0.0006401090649887919
Validation loss = 0.0009264246909879148
Validation loss = 0.0008955237572081387
Validation loss = 0.0009699866059236228
Fitting model 2 (0-based) in the ensemble of 5 models
Validation loss = 0.0006775513757020235
Validation loss = 0.0009267140412703156
Validation loss = 0.0007434061844833195
Validation loss = 0.0007355001871474087
Validation loss = 0.0005863141850568354
Validation loss = 0.0006251370068639517
Validation loss = 0.0006500061135739088
Validation loss = 0.0007338140858337283
Validation loss = 0.0007248920737765729
Fitting model 3 (0-based) in the ensemble of 5 models
Validation loss = 0.0011350749991834164
Validation loss = 0.0006390196504071355
Validation loss = 0.0008272427949123085
Validation loss = 0.0007131702732294798
Validation loss = 0.000550841330550611
Validation loss = 0.0007122399401850998
Validation loss = 0.00073288130806759
Validation loss = 0.0006844192976132035
Validation loss = 0.0006660941289737821
Fitting model 4 (0-based) in the ensemble of 5 models
Validation loss = 0.0007371400133706629
Validation loss = 0.000669892702717334
Validation loss = 0.0006232205196283758
Validation loss = 0.0006137334858067334
Validation loss = 0.0007149098091758788
Validation loss = 0.0006912982207722962
Validation loss = 0.0005830485606566072
Validation loss = 0.0006610188283957541
Validation loss = 0.0006099879392422736
Validation loss = 0.0006098321173340082
Validation loss = 0.0007568913861177862
Done fitting dynamics.
Updating randomness.
Done updating randomness.
Training policy using TRPO.
Re-initialize init_std.
Obtaining samples for iteration 0...
Obtaining samples for iteration 1...
Obtaining samples for iteration 2...
Obtaining samples for iteration 3...
Obtaining samples for iteration 4...
Obtaining samples for iteration 5...
Obtaining samples for iteration 6...
Obtaining samples for iteration 7...
Obtaining samples for iteration 8...
Obtaining samples for iteration 9...
Obtaining samples for iteration 10...
Obtaining samples for iteration 11...
Obtaining samples for iteration 12...
Obtaining samples for iteration 13...
Obtaining samples for iteration 14...
Obtaining samples for iteration 15...
Obtaining samples for iteration 16...
Obtaining samples for iteration 17...
Obtaining samples for iteration 18...
Obtaining samples for iteration 19...
Done training policy.
Generating on-policy rollouts.
Path 0 | total_timesteps 0.
Path 1 | total_timesteps 200.
Path 2 | total_timesteps 400.
Path 3 | total_timesteps 600.
Path 4 | total_timesteps 800.
Path 5 | total_timesteps 1000.
Path 6 | total_timesteps 1200.
Path 7 | total_timesteps 1400.
Path 8 | total_timesteps 1600.
Path 9 | total_timesteps 1800.
Path 10 | total_timesteps 2000.
Path 11 | total_timesteps 2200.
Path 12 | total_timesteps 2400.
Path 13 | total_timesteps 2600.
Path 14 | total_timesteps 2800.
Path 15 | total_timesteps 3000.
Path 16 | total_timesteps 3200.
Path 17 | total_timesteps 3400.
Path 18 | total_timesteps 3600.
Path 19 | total_timesteps 3800.
Path 20 | total_timesteps 4000.
Path 21 | total_timesteps 4200.
Path 22 | total_timesteps 4400.
Path 23 | total_timesteps 4600.
Path 24 | total_timesteps 4800.
Done generating on-policy rollouts.
Updating normalization.
Done updating normalization.
----------------------------
| AverageReturn | 170      |
| Iteration     | 17       |
| MaximumReturn | 199      |
| MinimumReturn | 88       |
| TotalSamples  | 63327    |
----------------------------
itr #18 | 
Fitting dynamics.
Fitting model 0 (0-based) in the ensemble of 5 models
Validation loss = 0.000739017385058105
Validation loss = 0.000612463743891567
Validation loss = 0.0011150911450386047
Validation loss = 0.0006005872855894268
Validation loss = 0.0008421179372817278
Validation loss = 0.0005971053033135831
Validation loss = 0.0006845534080639482
Validation loss = 0.0007938131457194686
Validation loss = 0.0006022941088303924
Validation loss = 0.0005856109200976789
Validation loss = 0.0006433932576328516
Validation loss = 0.0005304976948536932
Validation loss = 0.0005742216017097235
Validation loss = 0.0007681389688514173
Validation loss = 0.0006267009885050356
Validation loss = 0.0006512448890134692
Fitting model 1 (0-based) in the ensemble of 5 models
Validation loss = 0.000593302131164819
Validation loss = 0.001332943676970899
Validation loss = 0.0006375231314450502
Validation loss = 0.0008412673487327993
Validation loss = 0.0009294794290326536
Fitting model 2 (0-based) in the ensemble of 5 models
Validation loss = 0.0006428331253118813
Validation loss = 0.0008574976236559451
Validation loss = 0.0005970270722173154
Validation loss = 0.0005971916252747178
Validation loss = 0.0006736380746588111
Validation loss = 0.0007270554779097438
Validation loss = 0.0006294459453783929
Fitting model 3 (0-based) in the ensemble of 5 models
Validation loss = 0.0008934868965297937
Validation loss = 0.000841903907712549
Validation loss = 0.0007293634116649628
Validation loss = 0.000594854645896703
Validation loss = 0.0005991575890220702
Validation loss = 0.0009932380635291338
Validation loss = 0.0005726057570427656
Validation loss = 0.0006364132859744132
Validation loss = 0.0007274079252965748
Validation loss = 0.0006587757961824536
Validation loss = 0.0007690812344662845
Fitting model 4 (0-based) in the ensemble of 5 models
Validation loss = 0.0009080868912860751
Validation loss = 0.0006175473681651056
Validation loss = 0.0007489608833566308
Validation loss = 0.0007680654525756836
Validation loss = 0.0008638228755444288
Validation loss = 0.0006972182891331613
Done fitting dynamics.
Updating randomness.
Done updating randomness.
Training policy using TRPO.
Re-initialize init_std.
Obtaining samples for iteration 0...
Obtaining samples for iteration 1...
Obtaining samples for iteration 2...
Obtaining samples for iteration 3...
Obtaining samples for iteration 4...
Obtaining samples for iteration 5...
Obtaining samples for iteration 6...
Obtaining samples for iteration 7...
Obtaining samples for iteration 8...
Obtaining samples for iteration 9...
Obtaining samples for iteration 10...
Obtaining samples for iteration 11...
Obtaining samples for iteration 12...
Obtaining samples for iteration 13...
Obtaining samples for iteration 14...
Obtaining samples for iteration 15...
Obtaining samples for iteration 16...
Obtaining samples for iteration 17...
Obtaining samples for iteration 18...
Obtaining samples for iteration 19...
Done training policy.
Generating on-policy rollouts.
Path 0 | total_timesteps 0.
Path 1 | total_timesteps 200.
Path 2 | total_timesteps 400.
Path 3 | total_timesteps 600.
Path 4 | total_timesteps 800.
Path 5 | total_timesteps 1000.
Path 6 | total_timesteps 1200.
Path 7 | total_timesteps 1400.
Path 8 | total_timesteps 1600.
Path 9 | total_timesteps 1800.
Path 10 | total_timesteps 2000.
Path 11 | total_timesteps 2200.
Path 12 | total_timesteps 2400.
Path 13 | total_timesteps 2600.
Path 14 | total_timesteps 2800.
Path 15 | total_timesteps 3000.
Path 16 | total_timesteps 3200.
Path 17 | total_timesteps 3400.
Path 18 | total_timesteps 3600.
Path 19 | total_timesteps 3800.
Path 20 | total_timesteps 4000.
Path 21 | total_timesteps 4200.
Path 22 | total_timesteps 4400.
Path 23 | total_timesteps 4600.
Path 24 | total_timesteps 4800.
Done generating on-policy rollouts.
Updating normalization.
Done updating normalization.
----------------------------
| AverageReturn | 172      |
| Iteration     | 18       |
| MaximumReturn | 199      |
| MinimumReturn | 123      |
| TotalSamples  | 66660    |
----------------------------
itr #19 | 
Fitting dynamics.
Fitting model 0 (0-based) in the ensemble of 5 models
Validation loss = 0.0006806831806898117
Validation loss = 0.0010437797755002975
Validation loss = 0.0007136589265428483
Validation loss = 0.0006248284480534494
Validation loss = 0.000635401695035398
Validation loss = 0.0006170740816742182
Validation loss = 0.0005815323092974722
Validation loss = 0.0006832008948549628
Validation loss = 0.0005761388456448913
Validation loss = 0.0006639136117883027
Validation loss = 0.000589891744311899
Validation loss = 0.0005705869407393038
Validation loss = 0.0006715459167025983
Validation loss = 0.000566593836992979
Validation loss = 0.0006158174364827573
Validation loss = 0.000607242458499968
Validation loss = 0.0005934391519986093
Validation loss = 0.0006796324742026627
Fitting model 1 (0-based) in the ensemble of 5 models
Validation loss = 0.0005693930434063077
Validation loss = 0.0006673447205685079
Validation loss = 0.000761107075959444
Validation loss = 0.0005506236921064556
Validation loss = 0.0007097781635820866
Validation loss = 0.0005424281698651612
Validation loss = 0.0006776117370463908
Validation loss = 0.000892775715328753
Validation loss = 0.0005599693977274001
Validation loss = 0.001026695128530264
Fitting model 2 (0-based) in the ensemble of 5 models
Validation loss = 0.0006415096577256918
Validation loss = 0.0007325852639041841
Validation loss = 0.0006237644702196121
Validation loss = 0.0005569694330915809
Validation loss = 0.000672902911901474
Validation loss = 0.0005634396220557392
Validation loss = 0.000612432137131691
Validation loss = 0.0006647768313996494
Fitting model 3 (0-based) in the ensemble of 5 models
Validation loss = 0.0007950500003062189
Validation loss = 0.0007357875583693385
Validation loss = 0.0008961884304881096
Validation loss = 0.0009083599434234202
Validation loss = 0.0006442942540161312
Validation loss = 0.0006367368623614311
Validation loss = 0.0005539502017199993
Validation loss = 0.000970040971878916
Validation loss = 0.0006337914383038878
Validation loss = 0.0008672362309880555
Validation loss = 0.00066589709604159
Fitting model 4 (0-based) in the ensemble of 5 models
Validation loss = 0.000669524073600769
Validation loss = 0.0005887417355552316
Validation loss = 0.0006767321028746665
Validation loss = 0.0007135120104067028
Validation loss = 0.0005859779776073992
Validation loss = 0.0006202436052262783
Validation loss = 0.0007176412618719041
Validation loss = 0.0006114080897532403
Validation loss = 0.0005939588299952447
Done fitting dynamics.
Updating randomness.
Done updating randomness.
Training policy using TRPO.
Re-initialize init_std.
Obtaining samples for iteration 0...
Obtaining samples for iteration 1...
Obtaining samples for iteration 2...
Obtaining samples for iteration 3...
Obtaining samples for iteration 4...
Obtaining samples for iteration 5...
Obtaining samples for iteration 6...
Obtaining samples for iteration 7...
Obtaining samples for iteration 8...
Obtaining samples for iteration 9...
Obtaining samples for iteration 10...
Obtaining samples for iteration 11...
Obtaining samples for iteration 12...
Obtaining samples for iteration 13...
Obtaining samples for iteration 14...
Obtaining samples for iteration 15...
Obtaining samples for iteration 16...
Obtaining samples for iteration 17...
Obtaining samples for iteration 18...
Obtaining samples for iteration 19...
Done training policy.
Generating on-policy rollouts.
Path 0 | total_timesteps 0.
Path 1 | total_timesteps 200.
Path 2 | total_timesteps 400.
Path 3 | total_timesteps 600.
Path 4 | total_timesteps 800.
Path 5 | total_timesteps 1000.
Path 6 | total_timesteps 1200.
Path 7 | total_timesteps 1400.
Path 8 | total_timesteps 1600.
Path 9 | total_timesteps 1800.
Path 10 | total_timesteps 2000.
Path 11 | total_timesteps 2200.
Path 12 | total_timesteps 2400.
Path 13 | total_timesteps 2600.
Path 14 | total_timesteps 2800.
Path 15 | total_timesteps 3000.
Path 16 | total_timesteps 3200.
Path 17 | total_timesteps 3400.
Path 18 | total_timesteps 3600.
Path 19 | total_timesteps 3800.
Path 20 | total_timesteps 4000.
Path 21 | total_timesteps 4200.
Path 22 | total_timesteps 4400.
Path 23 | total_timesteps 4600.
Path 24 | total_timesteps 4800.
Done generating on-policy rollouts.
Updating normalization.
Done updating normalization.
----------------------------
| AverageReturn | 165      |
| Iteration     | 19       |
| MaximumReturn | 199      |
| MinimumReturn | 122      |
| TotalSamples  | 69993    |
----------------------------
itr #20 | 
Fitting dynamics.
Fitting model 0 (0-based) in the ensemble of 5 models
Validation loss = 0.0006905743503011763
Validation loss = 0.0005838834913447499
Validation loss = 0.0005296958843246102
Validation loss = 0.000701613025739789
Validation loss = 0.0006573978462256491
Validation loss = 0.000611528754234314
Validation loss = 0.0005654903943650424
Fitting model 1 (0-based) in the ensemble of 5 models
Validation loss = 0.0006751921027898788
Validation loss = 0.000638374884147197
Validation loss = 0.0006946056964807212
Validation loss = 0.000587104877922684
Validation loss = 0.0006194938323460519
Validation loss = 0.000584122899454087
Validation loss = 0.0006093305419199169
Validation loss = 0.0007434726576320827
Validation loss = 0.0005771844880655408
Validation loss = 0.001074017258360982
Validation loss = 0.0005847035790793598
Validation loss = 0.0009400067501701415
Validation loss = 0.0006623344379477203
Fitting model 2 (0-based) in the ensemble of 5 models
Validation loss = 0.0006190864369273186
Validation loss = 0.0006659635691903532
Validation loss = 0.0007991872844286263
Validation loss = 0.0005596885457634926
Validation loss = 0.0005862233811058104
Validation loss = 0.0005765034584328532
Validation loss = 0.0008259086753241718
Validation loss = 0.0005627054488286376
Fitting model 3 (0-based) in the ensemble of 5 models
Validation loss = 0.0009243398671969771
Validation loss = 0.000539825763553381
Validation loss = 0.000591340649407357
Validation loss = 0.0006660395883955061
Validation loss = 0.0005286322557367384
Validation loss = 0.0005674176500178874
Validation loss = 0.0006485069170594215
Validation loss = 0.0008795952890068293
Validation loss = 0.0006718005752190948
Fitting model 4 (0-based) in the ensemble of 5 models
Validation loss = 0.00060614402173087
Validation loss = 0.0006388269830495119
Validation loss = 0.0006627176189795136
Validation loss = 0.000569471507333219
Validation loss = 0.0007821349427103996
Validation loss = 0.0006693778559565544
Validation loss = 0.0007592818583361804
Validation loss = 0.0006503188633359969
Done fitting dynamics.
Updating randomness.
Done updating randomness.
Training policy using TRPO.
Re-initialize init_std.
Obtaining samples for iteration 0...
Obtaining samples for iteration 1...
Obtaining samples for iteration 2...
Obtaining samples for iteration 3...
Obtaining samples for iteration 4...
Obtaining samples for iteration 5...
Obtaining samples for iteration 6...
Obtaining samples for iteration 7...
Obtaining samples for iteration 8...
Obtaining samples for iteration 9...
Obtaining samples for iteration 10...
Obtaining samples for iteration 11...
Obtaining samples for iteration 12...
Obtaining samples for iteration 13...
Obtaining samples for iteration 14...
Obtaining samples for iteration 15...
Obtaining samples for iteration 16...
Obtaining samples for iteration 17...
Obtaining samples for iteration 18...
Obtaining samples for iteration 19...
Done training policy.
Generating on-policy rollouts.
Path 0 | total_timesteps 0.
Path 1 | total_timesteps 200.
Path 2 | total_timesteps 400.
Path 3 | total_timesteps 600.
Path 4 | total_timesteps 800.
Path 5 | total_timesteps 1000.
Path 6 | total_timesteps 1200.
Path 7 | total_timesteps 1400.
Path 8 | total_timesteps 1600.
Path 9 | total_timesteps 1800.
Path 10 | total_timesteps 2000.
Path 11 | total_timesteps 2200.
Path 12 | total_timesteps 2400.
Path 13 | total_timesteps 2600.
Path 14 | total_timesteps 2800.
Path 15 | total_timesteps 3000.
Path 16 | total_timesteps 3200.
Path 17 | total_timesteps 3400.
Path 18 | total_timesteps 3600.
Path 19 | total_timesteps 3800.
Path 20 | total_timesteps 4000.
Path 21 | total_timesteps 4200.
Path 22 | total_timesteps 4400.
Path 23 | total_timesteps 4600.
Path 24 | total_timesteps 4800.
Done generating on-policy rollouts.
Updating normalization.
Done updating normalization.
----------------------------
| AverageReturn | 171      |
| Iteration     | 20       |
| MaximumReturn | 199      |
| MinimumReturn | 126      |
| TotalSamples  | 73326    |
----------------------------
itr #21 | 
Fitting dynamics.
Fitting model 0 (0-based) in the ensemble of 5 models
Validation loss = 0.0006780278054066002
Validation loss = 0.0005965739255771041
Validation loss = 0.0007178502273745835
Validation loss = 0.0010099695064127445
Validation loss = 0.0005444461712613702
Validation loss = 0.0006019350839778781
Validation loss = 0.0005964910378679633
Validation loss = 0.0005893222987651825
Validation loss = 0.000646051368676126
Fitting model 1 (0-based) in the ensemble of 5 models
Validation loss = 0.0005719083710573614
Validation loss = 0.0006491316598840058
Validation loss = 0.0006076146964915097
Validation loss = 0.0005639962037093937
Validation loss = 0.0006982653867453337
Validation loss = 0.0006140706827864051
Validation loss = 0.0007202783017419279
Validation loss = 0.0008064194116741419
Fitting model 2 (0-based) in the ensemble of 5 models
Validation loss = 0.0005811203154735267
Validation loss = 0.0005668674712069333
Validation loss = 0.0009999428875744343
Validation loss = 0.0006105290376581252
Validation loss = 0.0005727072129957378
Validation loss = 0.0009360549156554043
Fitting model 3 (0-based) in the ensemble of 5 models
Validation loss = 0.0007497016340494156
Validation loss = 0.0006938543519936502
Validation loss = 0.0005529934423975646
Validation loss = 0.000657710013911128
Validation loss = 0.0005272346897982061
Validation loss = 0.0006738253869116306
Validation loss = 0.0005782168009318411
Validation loss = 0.0006532500265166163
Validation loss = 0.0005245422362349927
Validation loss = 0.0010212007910013199
Validation loss = 0.0005429873708635569
Validation loss = 0.0006626538815908134
Validation loss = 0.0007605584687553346
Fitting model 4 (0-based) in the ensemble of 5 models
Validation loss = 0.001038436545059085
Validation loss = 0.0005755003658123314
Validation loss = 0.0008815292967483401
Validation loss = 0.000719740753993392
Validation loss = 0.0005704042850993574
Validation loss = 0.0006523054908029735
Validation loss = 0.0006043719477020204
Validation loss = 0.0006645563407801092
Validation loss = 0.0006819494883529842
Done fitting dynamics.
Updating randomness.
Done updating randomness.
Training policy using TRPO.
Re-initialize init_std.
Obtaining samples for iteration 0...
Obtaining samples for iteration 1...
Obtaining samples for iteration 2...
Obtaining samples for iteration 3...
Obtaining samples for iteration 4...
Obtaining samples for iteration 5...
Obtaining samples for iteration 6...
Obtaining samples for iteration 7...
Obtaining samples for iteration 8...
Obtaining samples for iteration 9...
Obtaining samples for iteration 10...
Obtaining samples for iteration 11...
Obtaining samples for iteration 12...
Obtaining samples for iteration 13...
Obtaining samples for iteration 14...
Obtaining samples for iteration 15...
Obtaining samples for iteration 16...
Obtaining samples for iteration 17...
Obtaining samples for iteration 18...
Obtaining samples for iteration 19...
Done training policy.
Generating on-policy rollouts.
Path 0 | total_timesteps 0.
Path 1 | total_timesteps 200.
Path 2 | total_timesteps 400.
Path 3 | total_timesteps 600.
Path 4 | total_timesteps 800.
Path 5 | total_timesteps 1000.
Path 6 | total_timesteps 1200.
Path 7 | total_timesteps 1400.
Path 8 | total_timesteps 1600.
Path 9 | total_timesteps 1800.
Path 10 | total_timesteps 2000.
Path 11 | total_timesteps 2200.
Path 12 | total_timesteps 2400.
Path 13 | total_timesteps 2600.
Path 14 | total_timesteps 2800.
Path 15 | total_timesteps 3000.
Path 16 | total_timesteps 3200.
Path 17 | total_timesteps 3400.
Path 18 | total_timesteps 3600.
Path 19 | total_timesteps 3800.
Path 20 | total_timesteps 4000.
Path 21 | total_timesteps 4200.
Path 22 | total_timesteps 4400.
Path 23 | total_timesteps 4600.
Path 24 | total_timesteps 4800.
Done generating on-policy rollouts.
Updating normalization.
Done updating normalization.
----------------------------
| AverageReturn | 171      |
| Iteration     | 21       |
| MaximumReturn | 199      |
| MinimumReturn | 126      |
| TotalSamples  | 76659    |
----------------------------
itr #22 | 
Fitting dynamics.
Fitting model 0 (0-based) in the ensemble of 5 models
Validation loss = 0.0006425197934731841
Validation loss = 0.0007362641044892371
Validation loss = 0.0005949747865088284
Validation loss = 0.0006635414902120829
Validation loss = 0.0005765191745012999
Validation loss = 0.0006578591419383883
Validation loss = 0.0006020317086949944
Validation loss = 0.0005773520679213107
Validation loss = 0.0008182949386537075
Fitting model 1 (0-based) in the ensemble of 5 models
Validation loss = 0.0005673422710970044
Validation loss = 0.0006784018478356302
Validation loss = 0.0006244683754630387
Validation loss = 0.0006394423544406891
Validation loss = 0.0006167675019241869
Fitting model 2 (0-based) in the ensemble of 5 models
Validation loss = 0.0006548498058691621
Validation loss = 0.0006256471388041973
Validation loss = 0.0006617758772335947
Validation loss = 0.0006095910212025046
Validation loss = 0.0006677478668279946
Validation loss = 0.0006363340653479099
Validation loss = 0.0005551992799155414
Validation loss = 0.0005744927912019193
Validation loss = 0.0007123846444301307
Validation loss = 0.0010619431268423796
Validation loss = 0.0005502106505446136
Validation loss = 0.0008036000072024763
Validation loss = 0.0007780191954225302
Validation loss = 0.0005560553981922567
Validation loss = 0.0006191537249833345
Fitting model 3 (0-based) in the ensemble of 5 models
Validation loss = 0.0005937861860729754
Validation loss = 0.000979420728981495
Validation loss = 0.0005554306553676724
Validation loss = 0.0005609391955658793
Validation loss = 0.0005759095656685531
Validation loss = 0.0006559336907230318
Validation loss = 0.0005697456654161215
Fitting model 4 (0-based) in the ensemble of 5 models
Validation loss = 0.0006572000565938652
Validation loss = 0.000591984367929399
Validation loss = 0.0006769097526557744
Validation loss = 0.0005870605236850679
Validation loss = 0.0006785073783248663
Validation loss = 0.0007498433697037399
Validation loss = 0.0007418651948682964
Validation loss = 0.0005743556539528072
Validation loss = 0.0005848521250300109
Validation loss = 0.0005517277750186622
Validation loss = 0.0006780712865293026
Validation loss = 0.0008230881066992879
Validation loss = 0.0008237178553827107
Validation loss = 0.0005794926546514034
Done fitting dynamics.
Updating randomness.
Done updating randomness.
Training policy using TRPO.
Re-initialize init_std.
Obtaining samples for iteration 0...
Obtaining samples for iteration 1...
Obtaining samples for iteration 2...
Obtaining samples for iteration 3...
Obtaining samples for iteration 4...
Obtaining samples for iteration 5...
Obtaining samples for iteration 6...
Obtaining samples for iteration 7...
Obtaining samples for iteration 8...
Obtaining samples for iteration 9...
Obtaining samples for iteration 10...
Obtaining samples for iteration 11...
Obtaining samples for iteration 12...
Obtaining samples for iteration 13...
Obtaining samples for iteration 14...
Obtaining samples for iteration 15...
Obtaining samples for iteration 16...
Obtaining samples for iteration 17...
Obtaining samples for iteration 18...
Obtaining samples for iteration 19...
Done training policy.
Generating on-policy rollouts.
Path 0 | total_timesteps 0.
Path 1 | total_timesteps 200.
Path 2 | total_timesteps 400.
Path 3 | total_timesteps 600.
Path 4 | total_timesteps 800.
Path 5 | total_timesteps 1000.
Path 6 | total_timesteps 1200.
Path 7 | total_timesteps 1400.
Path 8 | total_timesteps 1600.
Path 9 | total_timesteps 1800.
Path 10 | total_timesteps 2000.
Path 11 | total_timesteps 2200.
Path 12 | total_timesteps 2400.
Path 13 | total_timesteps 2600.
Path 14 | total_timesteps 2800.
Path 15 | total_timesteps 3000.
Path 16 | total_timesteps 3200.
Path 17 | total_timesteps 3400.
Path 18 | total_timesteps 3600.
Path 19 | total_timesteps 3800.
Path 20 | total_timesteps 4000.
Path 21 | total_timesteps 4200.
Path 22 | total_timesteps 4400.
Path 23 | total_timesteps 4600.
Path 24 | total_timesteps 4800.
Done generating on-policy rollouts.
Updating normalization.
Done updating normalization.
----------------------------
| AverageReturn | 164      |
| Iteration     | 22       |
| MaximumReturn | 199      |
| MinimumReturn | 119      |
| TotalSamples  | 79992    |
----------------------------
itr #23 | 
Fitting dynamics.
Fitting model 0 (0-based) in the ensemble of 5 models
Validation loss = 0.000559011590667069
Validation loss = 0.0006514569977298379
Validation loss = 0.000614054617471993
Validation loss = 0.000671951740514487
Validation loss = 0.0005370674771256745
Validation loss = 0.0005370513536036015
Validation loss = 0.0006080045131966472
Validation loss = 0.0005564094753935933
Validation loss = 0.0006467004423029721
Validation loss = 0.0006123672937974334
Fitting model 1 (0-based) in the ensemble of 5 models
Validation loss = 0.0007057848270051181
Validation loss = 0.0007172694313339889
Validation loss = 0.0006117252632975578
Validation loss = 0.0007215949590317905
Validation loss = 0.000567756884265691
Validation loss = 0.0006170080741867423
Validation loss = 0.0006923637120053172
Validation loss = 0.0006479364237748086
Validation loss = 0.0009364594588987529
Fitting model 2 (0-based) in the ensemble of 5 models
Validation loss = 0.0009620978380553424
Validation loss = 0.0005713741993531585
Validation loss = 0.0006799417897127569
Validation loss = 0.0006202561198733747
Validation loss = 0.0006790802581235766
Validation loss = 0.0005438672378659248
Validation loss = 0.0005329065024852753
Validation loss = 0.000619920261669904
Validation loss = 0.000789494370110333
Validation loss = 0.0005477435770444572
Validation loss = 0.0006925439229235053
Fitting model 3 (0-based) in the ensemble of 5 models
Validation loss = 0.0006796380621381104
Validation loss = 0.0007095286855474114
Validation loss = 0.0007274852250702679
Validation loss = 0.0009315814822912216
Validation loss = 0.0006852123187854886
Fitting model 4 (0-based) in the ensemble of 5 models
Validation loss = 0.0005722186760976911
Validation loss = 0.0009559027967043221
Validation loss = 0.0005204934277571738
Validation loss = 0.000859629362821579
Validation loss = 0.0008443819242529571
Validation loss = 0.0005760489730164409
Validation loss = 0.0007170235039666295
Done fitting dynamics.
Updating randomness.
Done updating randomness.
Training policy using TRPO.
Re-initialize init_std.
Obtaining samples for iteration 0...
Obtaining samples for iteration 1...
Obtaining samples for iteration 2...
Obtaining samples for iteration 3...
Obtaining samples for iteration 4...
Obtaining samples for iteration 5...
Obtaining samples for iteration 6...
Obtaining samples for iteration 7...
Obtaining samples for iteration 8...
Obtaining samples for iteration 9...
Obtaining samples for iteration 10...
Obtaining samples for iteration 11...
Obtaining samples for iteration 12...
Obtaining samples for iteration 13...
Obtaining samples for iteration 14...
Obtaining samples for iteration 15...
Obtaining samples for iteration 16...
Obtaining samples for iteration 17...
Obtaining samples for iteration 18...
Obtaining samples for iteration 19...
Done training policy.
Generating on-policy rollouts.
Path 0 | total_timesteps 0.
Path 1 | total_timesteps 200.
Path 2 | total_timesteps 400.
Path 3 | total_timesteps 600.
Path 4 | total_timesteps 800.
Path 5 | total_timesteps 1000.
Path 6 | total_timesteps 1200.
Path 7 | total_timesteps 1400.
Path 8 | total_timesteps 1600.
Path 9 | total_timesteps 1800.
Path 10 | total_timesteps 2000.
Path 11 | total_timesteps 2200.
Path 12 | total_timesteps 2400.
Path 13 | total_timesteps 2600.
Path 14 | total_timesteps 2800.
Path 15 | total_timesteps 3000.
Path 16 | total_timesteps 3200.
Path 17 | total_timesteps 3400.
Path 18 | total_timesteps 3600.
Path 19 | total_timesteps 3800.
Path 20 | total_timesteps 4000.
Path 21 | total_timesteps 4200.
Path 22 | total_timesteps 4400.
Path 23 | total_timesteps 4600.
Path 24 | total_timesteps 4800.
Done generating on-policy rollouts.
Updating normalization.
Done updating normalization.
----------------------------
| AverageReturn | 173      |
| Iteration     | 23       |
| MaximumReturn | 199      |
| MinimumReturn | 112      |
| TotalSamples  | 83325    |
----------------------------
itr #24 | 
Fitting dynamics.
Fitting model 0 (0-based) in the ensemble of 5 models
Validation loss = 0.0007845801301300526
Validation loss = 0.0005620027077384293
Validation loss = 0.0005606908234767616
Validation loss = 0.0006247757701203227
Validation loss = 0.000624637003056705
Validation loss = 0.0005555522511713207
Validation loss = 0.0006657702615484595
Validation loss = 0.0005748713738285005
Validation loss = 0.0008497682283632457
Validation loss = 0.0005601175362244248
Fitting model 1 (0-based) in the ensemble of 5 models
Validation loss = 0.0005984927411191165
Validation loss = 0.0005950742634013295
Validation loss = 0.0007426469819620252
Validation loss = 0.0006332568009383976
Validation loss = 0.0007774026016704738
Validation loss = 0.0005976334796287119
Fitting model 2 (0-based) in the ensemble of 5 models
Validation loss = 0.000555624661501497
Validation loss = 0.0006377506069839001
Validation loss = 0.0008065136498771608
Validation loss = 0.0005288080428726971
Validation loss = 0.0006534389103762805
Validation loss = 0.0005945961456745863
Validation loss = 0.0005707120872102678
Validation loss = 0.00056227802997455
Fitting model 3 (0-based) in the ensemble of 5 models
Validation loss = 0.0006437554256990552
Validation loss = 0.0006453190580941737
Validation loss = 0.0005938615067861974
Validation loss = 0.0006119640893302858
Validation loss = 0.0006619540508836508
Validation loss = 0.0005743175861425698
Validation loss = 0.0005231703398749232
Validation loss = 0.0005414678016677499
Validation loss = 0.0006238036439754069
Validation loss = 0.0006678423960693181
Validation loss = 0.0006003660964779556
Fitting model 4 (0-based) in the ensemble of 5 models
Validation loss = 0.0005394125473685563
Validation loss = 0.0006077588768675923
Validation loss = 0.0005980967544019222
Validation loss = 0.0007827625377103686
Validation loss = 0.000688133470248431
Done fitting dynamics.
Updating randomness.
Done updating randomness.
Training policy using TRPO.
Re-initialize init_std.
Obtaining samples for iteration 0...
Obtaining samples for iteration 1...
Obtaining samples for iteration 2...
Obtaining samples for iteration 3...
Obtaining samples for iteration 4...
Obtaining samples for iteration 5...
Obtaining samples for iteration 6...
Obtaining samples for iteration 7...
Obtaining samples for iteration 8...
Obtaining samples for iteration 9...
Obtaining samples for iteration 10...
Obtaining samples for iteration 11...
Obtaining samples for iteration 12...
Obtaining samples for iteration 13...
Obtaining samples for iteration 14...
Obtaining samples for iteration 15...
Obtaining samples for iteration 16...
Obtaining samples for iteration 17...
Obtaining samples for iteration 18...
Obtaining samples for iteration 19...
Done training policy.
Generating on-policy rollouts.
Path 0 | total_timesteps 0.
Path 1 | total_timesteps 200.
Path 2 | total_timesteps 400.
Path 3 | total_timesteps 600.
Path 4 | total_timesteps 800.
Path 5 | total_timesteps 1000.
Path 6 | total_timesteps 1200.
Path 7 | total_timesteps 1400.
Path 8 | total_timesteps 1600.
Path 9 | total_timesteps 1800.
Path 10 | total_timesteps 2000.
Path 11 | total_timesteps 2200.
Path 12 | total_timesteps 2400.
Path 13 | total_timesteps 2600.
Path 14 | total_timesteps 2800.
Path 15 | total_timesteps 3000.
Path 16 | total_timesteps 3200.
Path 17 | total_timesteps 3400.
Path 18 | total_timesteps 3600.
Path 19 | total_timesteps 3800.
Path 20 | total_timesteps 4000.
Path 21 | total_timesteps 4200.
Path 22 | total_timesteps 4400.
Path 23 | total_timesteps 4600.
Path 24 | total_timesteps 4800.
Done generating on-policy rollouts.
Updating normalization.
Done updating normalization.
----------------------------
| AverageReturn | 174      |
| Iteration     | 24       |
| MaximumReturn | 199      |
| MinimumReturn | 122      |
| TotalSamples  | 86658    |
----------------------------
itr #25 | 
Fitting dynamics.
Fitting model 0 (0-based) in the ensemble of 5 models
Validation loss = 0.0007099045906215906
Validation loss = 0.000610352901276201
Validation loss = 0.0006575117586180568
Validation loss = 0.000620125385466963
Validation loss = 0.0005353651358745992
Validation loss = 0.0006251305458135903
Validation loss = 0.0005611097440123558
Validation loss = 0.0005855712224729359
Validation loss = 0.0005679657915607095
Fitting model 1 (0-based) in the ensemble of 5 models
Validation loss = 0.0007045381935313344
Validation loss = 0.0006378391408361495
Validation loss = 0.0005554097588174045
Validation loss = 0.0010951767908409238
Validation loss = 0.0005839262739755213
Validation loss = 0.000571082578971982
Validation loss = 0.0006377912941388786
Fitting model 2 (0-based) in the ensemble of 5 models
Validation loss = 0.0006439421558752656
Validation loss = 0.0006412678048945963
Validation loss = 0.0005167117342352867
Validation loss = 0.0006092453841120005
Validation loss = 0.0006355891237035394
Validation loss = 0.0008506554877385497
Validation loss = 0.0005885876598767936
Fitting model 3 (0-based) in the ensemble of 5 models
Validation loss = 0.0005654259002767503
Validation loss = 0.0007731318473815918
Validation loss = 0.0007392977131530643
Validation loss = 0.000626355642452836
Validation loss = 0.0005672310944646597
Fitting model 4 (0-based) in the ensemble of 5 models
Validation loss = 0.0006111117545515299
Validation loss = 0.0005947785102762282
Validation loss = 0.0008410777663812041
Validation loss = 0.0006159568438306451
Validation loss = 0.0006697956123389304
Validation loss = 0.0005374329630285501
Validation loss = 0.0005923088756389916
Validation loss = 0.0005517806275747716
Validation loss = 0.0006014958489686251
Validation loss = 0.0006006680778227746
Done fitting dynamics.
Updating randomness.
Done updating randomness.
Training policy using TRPO.
Re-initialize init_std.
Obtaining samples for iteration 0...
Obtaining samples for iteration 1...
Obtaining samples for iteration 2...
Obtaining samples for iteration 3...
Obtaining samples for iteration 4...
Obtaining samples for iteration 5...
Obtaining samples for iteration 6...
Obtaining samples for iteration 7...
Obtaining samples for iteration 8...
Obtaining samples for iteration 9...
Obtaining samples for iteration 10...
Obtaining samples for iteration 11...
Obtaining samples for iteration 12...
Obtaining samples for iteration 13...
Obtaining samples for iteration 14...
Obtaining samples for iteration 15...
Obtaining samples for iteration 16...
Obtaining samples for iteration 17...
Obtaining samples for iteration 18...
Obtaining samples for iteration 19...
Done training policy.
Generating on-policy rollouts.
Path 0 | total_timesteps 0.
Path 1 | total_timesteps 200.
Path 2 | total_timesteps 400.
Path 3 | total_timesteps 600.
Path 4 | total_timesteps 800.
Path 5 | total_timesteps 1000.
Path 6 | total_timesteps 1200.
Path 7 | total_timesteps 1400.
Path 8 | total_timesteps 1600.
Path 9 | total_timesteps 1800.
Path 10 | total_timesteps 2000.
Path 11 | total_timesteps 2200.
Path 12 | total_timesteps 2400.
Path 13 | total_timesteps 2600.
Path 14 | total_timesteps 2800.
Path 15 | total_timesteps 3000.
Path 16 | total_timesteps 3200.
Path 17 | total_timesteps 3400.
Path 18 | total_timesteps 3600.
Path 19 | total_timesteps 3800.
Path 20 | total_timesteps 4000.
Path 21 | total_timesteps 4200.
Path 22 | total_timesteps 4400.
Path 23 | total_timesteps 4600.
Path 24 | total_timesteps 4800.
Done generating on-policy rollouts.
Updating normalization.
Done updating normalization.
----------------------------
| AverageReturn | 164      |
| Iteration     | 25       |
| MaximumReturn | 198      |
| MinimumReturn | 115      |
| TotalSamples  | 89991    |
----------------------------
itr #26 | 
Fitting dynamics.
Fitting model 0 (0-based) in the ensemble of 5 models
Validation loss = 0.0005935585941188037
Validation loss = 0.0005062998388893902
Validation loss = 0.0005566458567045629
Validation loss = 0.0005981175345368683
Validation loss = 0.0005815312033519149
Validation loss = 0.0005702897324226797
Fitting model 1 (0-based) in the ensemble of 5 models
Validation loss = 0.0005765743553638458
Validation loss = 0.0005167908384464681
Validation loss = 0.0006347498274408281
Validation loss = 0.0005384922842495143
Validation loss = 0.0005353782325983047
Validation loss = 0.0005244741914793849
Fitting model 2 (0-based) in the ensemble of 5 models
Validation loss = 0.0005447569419629872
Validation loss = 0.0009436972322873771
Validation loss = 0.000646447588223964
Validation loss = 0.0005267272936180234
Validation loss = 0.000508794910274446
Validation loss = 0.0005580845172517002
Validation loss = 0.0006864608149044216
Validation loss = 0.0007352393586188555
Validation loss = 0.0006005811155773699
Fitting model 3 (0-based) in the ensemble of 5 models
Validation loss = 0.0005896000657230616
Validation loss = 0.0006329072639346123
Validation loss = 0.000542205641977489
Validation loss = 0.0006169404368847609
Validation loss = 0.0006925275665707886
Validation loss = 0.0005217589205130935
Validation loss = 0.0005749079864472151
Validation loss = 0.0005566634354181588
Validation loss = 0.0006162048084661365
Validation loss = 0.0006514372653327882
Fitting model 4 (0-based) in the ensemble of 5 models
Validation loss = 0.0006105090724304318
Validation loss = 0.0005569745553657413
Validation loss = 0.0005425788694992661
Validation loss = 0.0005466892616823316
Validation loss = 0.0005371957086026669
Validation loss = 0.0005530448397621512
Validation loss = 0.0006162383360788226
Validation loss = 0.0006814816733822227
Validation loss = 0.0007967398269101977
Done fitting dynamics.
Updating randomness.
Done updating randomness.
Training policy using TRPO.
Re-initialize init_std.
Obtaining samples for iteration 0...
Obtaining samples for iteration 1...
Obtaining samples for iteration 2...
Obtaining samples for iteration 3...
Obtaining samples for iteration 4...
Obtaining samples for iteration 5...
Obtaining samples for iteration 6...
Obtaining samples for iteration 7...
Obtaining samples for iteration 8...
Obtaining samples for iteration 9...
Obtaining samples for iteration 10...
Obtaining samples for iteration 11...
Obtaining samples for iteration 12...
Obtaining samples for iteration 13...
Obtaining samples for iteration 14...
Obtaining samples for iteration 15...
Obtaining samples for iteration 16...
Obtaining samples for iteration 17...
Obtaining samples for iteration 18...
Obtaining samples for iteration 19...
Done training policy.
Generating on-policy rollouts.
Path 0 | total_timesteps 0.
Path 1 | total_timesteps 200.
Path 2 | total_timesteps 400.
Path 3 | total_timesteps 600.
Path 4 | total_timesteps 800.
Path 5 | total_timesteps 1000.
Path 6 | total_timesteps 1200.
Path 7 | total_timesteps 1400.
Path 8 | total_timesteps 1600.
Path 9 | total_timesteps 1800.
Path 10 | total_timesteps 2000.
Path 11 | total_timesteps 2200.
Path 12 | total_timesteps 2400.
Path 13 | total_timesteps 2600.
Path 14 | total_timesteps 2800.
Path 15 | total_timesteps 3000.
Path 16 | total_timesteps 3200.
Path 17 | total_timesteps 3400.
Path 18 | total_timesteps 3600.
Path 19 | total_timesteps 3800.
Path 20 | total_timesteps 4000.
Path 21 | total_timesteps 4200.
Path 22 | total_timesteps 4400.
Path 23 | total_timesteps 4600.
Path 24 | total_timesteps 4800.
Done generating on-policy rollouts.
Updating normalization.
Done updating normalization.
----------------------------
| AverageReturn | 166      |
| Iteration     | 26       |
| MaximumReturn | 198      |
| MinimumReturn | 124      |
| TotalSamples  | 93324    |
----------------------------
itr #27 | 
Fitting dynamics.
Fitting model 0 (0-based) in the ensemble of 5 models
Validation loss = 0.0005481878179125488
Validation loss = 0.0005052389460615814
Validation loss = 0.0005037795635871589
Validation loss = 0.0005466986331157386
Validation loss = 0.0005955863161943853
Validation loss = 0.00057417550124228
Validation loss = 0.0005740600172430277
Fitting model 1 (0-based) in the ensemble of 5 models
Validation loss = 0.0006280539673753083
Validation loss = 0.0005898133968003094
Validation loss = 0.000652496877592057
Validation loss = 0.0011411773739382625
Validation loss = 0.0008098474354483187
Validation loss = 0.0009024696191772819
Fitting model 2 (0-based) in the ensemble of 5 models
Validation loss = 0.0006016648840159178
Validation loss = 0.0005915384972468019
Validation loss = 0.0005762021755799651
Validation loss = 0.0006030267686583102
Validation loss = 0.000653546885587275
Validation loss = 0.0005644733319059014
Validation loss = 0.0005870190798304975
Validation loss = 0.0005633123801089823
Validation loss = 0.0006780994008295238
Validation loss = 0.0005233457777649164
Validation loss = 0.000640501850284636
Validation loss = 0.0006007920601405203
Validation loss = 0.000571716227568686
Validation loss = 0.0005348235717974603
Fitting model 3 (0-based) in the ensemble of 5 models
Validation loss = 0.0006315559730865061
Validation loss = 0.0005678811576217413
Validation loss = 0.0005413179169408977
Validation loss = 0.0006187899271026254
Validation loss = 0.0006024573813192546
Validation loss = 0.0005166783812455833
Validation loss = 0.0005731464480049908
Validation loss = 0.0005460809334181249
Validation loss = 0.0005859722732566297
Validation loss = 0.0005260420730337501
Fitting model 4 (0-based) in the ensemble of 5 models
Validation loss = 0.001317758928053081
Validation loss = 0.0005387580604292452
Validation loss = 0.0007396048749797046
Validation loss = 0.000546549039427191
Validation loss = 0.0006304013659246266
Validation loss = 0.0006486743804998696
Done fitting dynamics.
Updating randomness.
Done updating randomness.
Training policy using TRPO.
Re-initialize init_std.
Obtaining samples for iteration 0...
Obtaining samples for iteration 1...
Obtaining samples for iteration 2...
Obtaining samples for iteration 3...
Obtaining samples for iteration 4...
Obtaining samples for iteration 5...
Obtaining samples for iteration 6...
Obtaining samples for iteration 7...
Obtaining samples for iteration 8...
Obtaining samples for iteration 9...
Obtaining samples for iteration 10...
Obtaining samples for iteration 11...
Obtaining samples for iteration 12...
Obtaining samples for iteration 13...
Obtaining samples for iteration 14...
Obtaining samples for iteration 15...
Obtaining samples for iteration 16...
Obtaining samples for iteration 17...
Obtaining samples for iteration 18...
Obtaining samples for iteration 19...
Done training policy.
Generating on-policy rollouts.
Path 0 | total_timesteps 0.
Path 1 | total_timesteps 200.
Path 2 | total_timesteps 400.
Path 3 | total_timesteps 600.
Path 4 | total_timesteps 800.
Path 5 | total_timesteps 1000.
Path 6 | total_timesteps 1200.
Path 7 | total_timesteps 1400.
Path 8 | total_timesteps 1600.
Path 9 | total_timesteps 1800.
Path 10 | total_timesteps 2000.
Path 11 | total_timesteps 2200.
Path 12 | total_timesteps 2400.
Path 13 | total_timesteps 2600.
Path 14 | total_timesteps 2800.
Path 15 | total_timesteps 3000.
Path 16 | total_timesteps 3200.
Path 17 | total_timesteps 3400.
Path 18 | total_timesteps 3600.
Path 19 | total_timesteps 3800.
Path 20 | total_timesteps 4000.
Path 21 | total_timesteps 4200.
Path 22 | total_timesteps 4400.
Path 23 | total_timesteps 4600.
Path 24 | total_timesteps 4800.
Done generating on-policy rollouts.
Updating normalization.
Done updating normalization.
----------------------------
| AverageReturn | 171      |
| Iteration     | 27       |
| MaximumReturn | 199      |
| MinimumReturn | 132      |
| TotalSamples  | 96657    |
----------------------------
itr #28 | 
Fitting dynamics.
Fitting model 0 (0-based) in the ensemble of 5 models
Validation loss = 0.0006058616563677788
Validation loss = 0.0005503015709109604
Validation loss = 0.0005922910640947521
Validation loss = 0.0005233717965893447
Validation loss = 0.0005534327938221395
Validation loss = 0.0006045426707714796
Validation loss = 0.0005271412082947791
Validation loss = 0.0006323980051092803
Fitting model 1 (0-based) in the ensemble of 5 models
Validation loss = 0.000847977411467582
Validation loss = 0.0006179013289511204
Validation loss = 0.0005726764793507755
Validation loss = 0.0009258938953280449
Validation loss = 0.001102233654819429
Validation loss = 0.000548678741324693
Validation loss = 0.0005831863381899893
Validation loss = 0.0006462654564529657
Validation loss = 0.0005380365182645619
Validation loss = 0.0006283524562604725
Validation loss = 0.0005258559831418097
Validation loss = 0.0005543931620195508
Validation loss = 0.0005876452196389437
Validation loss = 0.000559166306629777
Validation loss = 0.0006072802934795618
Fitting model 2 (0-based) in the ensemble of 5 models
Validation loss = 0.0006447955965995789
Validation loss = 0.0006399833364412189
Validation loss = 0.000494715350214392
Validation loss = 0.0005503513384610415
Validation loss = 0.0005769461276941001
Validation loss = 0.0005822120001539588
Validation loss = 0.0006081867031753063
Fitting model 3 (0-based) in the ensemble of 5 models
Validation loss = 0.0005354579188860953
Validation loss = 0.0005212826654314995
Validation loss = 0.0007129638106562197
Validation loss = 0.0005668826051987708
Validation loss = 0.0005154328537173569
Validation loss = 0.0005370701546780765
Validation loss = 0.0006035413243807852
Validation loss = 0.0005787631962448359
Validation loss = 0.0006661742809228599
Fitting model 4 (0-based) in the ensemble of 5 models
Validation loss = 0.000689840700943023
Validation loss = 0.0005973613006062806
Validation loss = 0.0006772687775082886
Validation loss = 0.000544889597222209
Validation loss = 0.0007197482045739889
Validation loss = 0.0007073887973092496
Validation loss = 0.0005011705216020346
Validation loss = 0.0005395689513534307
Validation loss = 0.0005277690361253917
Validation loss = 0.000690653279889375
Validation loss = 0.0005777087644673884
Done fitting dynamics.
Updating randomness.
Done updating randomness.
Training policy using TRPO.
Re-initialize init_std.
Obtaining samples for iteration 0...
Obtaining samples for iteration 1...
Obtaining samples for iteration 2...
Obtaining samples for iteration 3...
Obtaining samples for iteration 4...
Obtaining samples for iteration 5...
Obtaining samples for iteration 6...
Obtaining samples for iteration 7...
Obtaining samples for iteration 8...
Obtaining samples for iteration 9...
Obtaining samples for iteration 10...
Obtaining samples for iteration 11...
Obtaining samples for iteration 12...
Obtaining samples for iteration 13...
Obtaining samples for iteration 14...
Obtaining samples for iteration 15...
Obtaining samples for iteration 16...
Obtaining samples for iteration 17...
Obtaining samples for iteration 18...
Obtaining samples for iteration 19...
Done training policy.
Generating on-policy rollouts.
Path 0 | total_timesteps 0.
Path 1 | total_timesteps 200.
Path 2 | total_timesteps 400.
Path 3 | total_timesteps 600.
Path 4 | total_timesteps 800.
Path 5 | total_timesteps 1000.
Path 6 | total_timesteps 1200.
Path 7 | total_timesteps 1400.
Path 8 | total_timesteps 1600.
Path 9 | total_timesteps 1800.
Path 10 | total_timesteps 2000.
Path 11 | total_timesteps 2200.
Path 12 | total_timesteps 2400.
Path 13 | total_timesteps 2600.
Path 14 | total_timesteps 2800.
Path 15 | total_timesteps 3000.
Path 16 | total_timesteps 3200.
Path 17 | total_timesteps 3400.
Path 18 | total_timesteps 3600.
Path 19 | total_timesteps 3800.
Path 20 | total_timesteps 4000.
Path 21 | total_timesteps 4200.
Path 22 | total_timesteps 4400.
Path 23 | total_timesteps 4600.
Path 24 | total_timesteps 4800.
Done generating on-policy rollouts.
Updating normalization.
Done updating normalization.
----------------------------
| AverageReturn | 165      |
| Iteration     | 28       |
| MaximumReturn | 199      |
| MinimumReturn | 125      |
| TotalSamples  | 99990    |
----------------------------
itr #29 | 
Fitting dynamics.
Fitting model 0 (0-based) in the ensemble of 5 models
Validation loss = 0.0005391957820393145
Validation loss = 0.0005626257043331861
Validation loss = 0.0006040611187927425
Validation loss = 0.0005003221449442208
Validation loss = 0.0005042501143179834
Validation loss = 0.0005534381489269435
Validation loss = 0.0006787627353332937
Validation loss = 0.0005450879689306021
Fitting model 1 (0-based) in the ensemble of 5 models
Validation loss = 0.0005506639718078077
Validation loss = 0.0005411094170995057
Validation loss = 0.0005378011846914887
Validation loss = 0.0005359960487112403
Validation loss = 0.0004999697557650506
Validation loss = 0.0005646133213303983
Validation loss = 0.0006087534711696208
Validation loss = 0.0006398360710591078
Validation loss = 0.0007792633841745555
Fitting model 2 (0-based) in the ensemble of 5 models
Validation loss = 0.0005448959418572485
Validation loss = 0.0005348735139705241
Validation loss = 0.0005682617193087935
Validation loss = 0.0005411874153651297
Validation loss = 0.0005120054120197892
Validation loss = 0.0005740704946219921
Validation loss = 0.0006670813309028745
Validation loss = 0.0005330618587322533
Validation loss = 0.0006088843801990151
Fitting model 3 (0-based) in the ensemble of 5 models
Validation loss = 0.0005800629151053727
Validation loss = 0.0005611177766695619
Validation loss = 0.0005208945949561894
Validation loss = 0.0006625173264183104
Validation loss = 0.0005954631487838924
Validation loss = 0.0006154708098620176
Validation loss = 0.0005070756888017058
Validation loss = 0.001006858074106276
Validation loss = 0.0007220314582809806
Validation loss = 0.0005312884459272027
Validation loss = 0.0005163722671568394
Fitting model 4 (0-based) in the ensemble of 5 models
Validation loss = 0.0005730933044105768
Validation loss = 0.0005472641787491739
Validation loss = 0.0006585211958736181
Validation loss = 0.0006518831360153854
Validation loss = 0.0005207225913181901
Validation loss = 0.0005411443999037147
Validation loss = 0.0005347420810721815
Validation loss = 0.000588960770983249
Validation loss = 0.0005128558841533959
Validation loss = 0.0005956496461294591
Validation loss = 0.0005846057902090251
Validation loss = 0.0005400539375841618
Validation loss = 0.0005866012652404606
Done fitting dynamics.
Updating randomness.
Done updating randomness.
Training policy using TRPO.
Re-initialize init_std.
Obtaining samples for iteration 0...
Obtaining samples for iteration 1...
Obtaining samples for iteration 2...
Obtaining samples for iteration 3...
Obtaining samples for iteration 4...
Obtaining samples for iteration 5...
Obtaining samples for iteration 6...
Obtaining samples for iteration 7...
Obtaining samples for iteration 8...
Obtaining samples for iteration 9...
Obtaining samples for iteration 10...
Obtaining samples for iteration 11...
Obtaining samples for iteration 12...
Obtaining samples for iteration 13...
Obtaining samples for iteration 14...
Obtaining samples for iteration 15...
Obtaining samples for iteration 16...
Obtaining samples for iteration 17...
Obtaining samples for iteration 18...
Obtaining samples for iteration 19...
Done training policy.
Generating on-policy rollouts.
Path 0 | total_timesteps 0.
Path 1 | total_timesteps 200.
Path 2 | total_timesteps 400.
Path 3 | total_timesteps 600.
Path 4 | total_timesteps 800.
Path 5 | total_timesteps 1000.
Path 6 | total_timesteps 1200.
Path 7 | total_timesteps 1400.
Path 8 | total_timesteps 1600.
Path 9 | total_timesteps 1800.
Path 10 | total_timesteps 2000.
Path 11 | total_timesteps 2200.
Path 12 | total_timesteps 2400.
Path 13 | total_timesteps 2600.
Path 14 | total_timesteps 2800.
Path 15 | total_timesteps 3000.
Path 16 | total_timesteps 3200.
Path 17 | total_timesteps 3400.
Path 18 | total_timesteps 3600.
Path 19 | total_timesteps 3800.
Path 20 | total_timesteps 4000.
Path 21 | total_timesteps 4200.
Path 22 | total_timesteps 4400.
Path 23 | total_timesteps 4600.
Path 24 | total_timesteps 4800.
Done generating on-policy rollouts.
Updating normalization.
Done updating normalization.
----------------------------
| AverageReturn | 172      |
| Iteration     | 29       |
| MaximumReturn | 199      |
| MinimumReturn | 127      |
| TotalSamples  | 103323   |
----------------------------
itr #30 | 
Fitting dynamics.
Fitting model 0 (0-based) in the ensemble of 5 models
Validation loss = 0.0005441384273581207
Validation loss = 0.0004961088416166604
Validation loss = 0.0005333053413778543
Validation loss = 0.0005688372766599059
Validation loss = 0.000551250297576189
Validation loss = 0.0005083776777610183
Fitting model 1 (0-based) in the ensemble of 5 models
Validation loss = 0.0006096725119277835
Validation loss = 0.0006178705370984972
Validation loss = 0.000837349274661392
Validation loss = 0.0005484850262291729
Validation loss = 0.0005548751214519143
Validation loss = 0.0006671103765256703
Validation loss = 0.0006678800564259291
Validation loss = 0.0006496108835563064
Fitting model 2 (0-based) in the ensemble of 5 models
Validation loss = 0.0005490551702678204
Validation loss = 0.0007091437000781298
Validation loss = 0.00067346659488976
Validation loss = 0.000572813383769244
Validation loss = 0.0007186161819845438
Fitting model 3 (0-based) in the ensemble of 5 models
Validation loss = 0.0006481504533439875
Validation loss = 0.0006447096820920706
Validation loss = 0.0005437883082777262
Validation loss = 0.0006287273135967553
Validation loss = 0.0005505812005139887
Validation loss = 0.0005360243958421052
Validation loss = 0.0006667862762697041
Validation loss = 0.0008249009842984378
Validation loss = 0.0005694899009540677
Validation loss = 0.0005703775677829981
Fitting model 4 (0-based) in the ensemble of 5 models
Validation loss = 0.0005299173062667251
Validation loss = 0.0006262284587137401
Validation loss = 0.0005160383298061788
Validation loss = 0.0005328301922418177
Validation loss = 0.000532873731572181
Validation loss = 0.0005735604208894074
Validation loss = 0.0005721678026020527
Done fitting dynamics.
Updating randomness.
Done updating randomness.
Training policy using TRPO.
Re-initialize init_std.
Obtaining samples for iteration 0...
Obtaining samples for iteration 1...
Obtaining samples for iteration 2...
Obtaining samples for iteration 3...
Obtaining samples for iteration 4...
Obtaining samples for iteration 5...
Obtaining samples for iteration 6...
Obtaining samples for iteration 7...
Obtaining samples for iteration 8...
Obtaining samples for iteration 9...
Obtaining samples for iteration 10...
Obtaining samples for iteration 11...
Obtaining samples for iteration 12...
Obtaining samples for iteration 13...
Obtaining samples for iteration 14...
Obtaining samples for iteration 15...
Obtaining samples for iteration 16...
Obtaining samples for iteration 17...
Obtaining samples for iteration 18...
Obtaining samples for iteration 19...
Done training policy.
Generating on-policy rollouts.
Path 0 | total_timesteps 0.
Path 1 | total_timesteps 200.
Path 2 | total_timesteps 400.
Path 3 | total_timesteps 600.
Path 4 | total_timesteps 800.
Path 5 | total_timesteps 1000.
Path 6 | total_timesteps 1200.
Path 7 | total_timesteps 1400.
Path 8 | total_timesteps 1600.
Path 9 | total_timesteps 1800.
Path 10 | total_timesteps 2000.
Path 11 | total_timesteps 2200.
Path 12 | total_timesteps 2400.
Path 13 | total_timesteps 2600.
Path 14 | total_timesteps 2800.
Path 15 | total_timesteps 3000.
Path 16 | total_timesteps 3200.
Path 17 | total_timesteps 3400.
Path 18 | total_timesteps 3600.
Path 19 | total_timesteps 3800.
Path 20 | total_timesteps 4000.
Path 21 | total_timesteps 4200.
Path 22 | total_timesteps 4400.
Path 23 | total_timesteps 4600.
Path 24 | total_timesteps 4800.
Done generating on-policy rollouts.
Updating normalization.
Done updating normalization.
----------------------------
| AverageReturn | 172      |
| Iteration     | 30       |
| MaximumReturn | 199      |
| MinimumReturn | 127      |
| TotalSamples  | 106656   |
----------------------------
itr #31 | 
Fitting dynamics.
Fitting model 0 (0-based) in the ensemble of 5 models
Validation loss = 0.0005352850421331823
Validation loss = 0.0005336037720553577
Validation loss = 0.0005978362169116735
Validation loss = 0.0005562838050536811
Validation loss = 0.0005758916959166527
Validation loss = 0.0005939953844062984
Fitting model 1 (0-based) in the ensemble of 5 models
Validation loss = 0.0005854106275364757
Validation loss = 0.0007610280299559236
Validation loss = 0.000507890887092799
Validation loss = 0.0005898593808524311
Validation loss = 0.0005849290173500776
Validation loss = 0.0005764116067439318
Validation loss = 0.0005405964329838753
Fitting model 2 (0-based) in the ensemble of 5 models
Validation loss = 0.000582776207011193
Validation loss = 0.0007234529475681484
Validation loss = 0.000516363768838346
Validation loss = 0.0005054131615906954
Validation loss = 0.0005246271612122655
Validation loss = 0.0005372517043724656
Validation loss = 0.0006200217758305371
Validation loss = 0.0006476087728515267
Fitting model 3 (0-based) in the ensemble of 5 models
Validation loss = 0.0005103333969600499
Validation loss = 0.0005078614340163767
Validation loss = 0.00052566675003618
Validation loss = 0.0005240502068772912
Validation loss = 0.0005781248328275979
Validation loss = 0.0006070577073842287
Fitting model 4 (0-based) in the ensemble of 5 models
Validation loss = 0.0005443617119453847
Validation loss = 0.0005686208023689687
Validation loss = 0.0005907464656047523
Validation loss = 0.000499263871461153
Validation loss = 0.0005820831283926964
Validation loss = 0.0005671903491020203
Validation loss = 0.000513453793246299
Validation loss = 0.0005125846364535391
Done fitting dynamics.
Updating randomness.
Done updating randomness.
Training policy using TRPO.
Re-initialize init_std.
Obtaining samples for iteration 0...
Obtaining samples for iteration 1...
Obtaining samples for iteration 2...
Obtaining samples for iteration 3...
Obtaining samples for iteration 4...
Obtaining samples for iteration 5...
Obtaining samples for iteration 6...
Obtaining samples for iteration 7...
Obtaining samples for iteration 8...
Obtaining samples for iteration 9...
Obtaining samples for iteration 10...
Obtaining samples for iteration 11...
Obtaining samples for iteration 12...
Obtaining samples for iteration 13...
Obtaining samples for iteration 14...
Obtaining samples for iteration 15...
Obtaining samples for iteration 16...
Obtaining samples for iteration 17...
Obtaining samples for iteration 18...
Obtaining samples for iteration 19...
Done training policy.
Generating on-policy rollouts.
Path 0 | total_timesteps 0.
Path 1 | total_timesteps 200.
Path 2 | total_timesteps 400.
Path 3 | total_timesteps 600.
Path 4 | total_timesteps 800.
Path 5 | total_timesteps 1000.
Path 6 | total_timesteps 1200.
Path 7 | total_timesteps 1400.
Path 8 | total_timesteps 1600.
Path 9 | total_timesteps 1800.
Path 10 | total_timesteps 2000.
Path 11 | total_timesteps 2200.
Path 12 | total_timesteps 2400.
Path 13 | total_timesteps 2600.
Path 14 | total_timesteps 2800.
Path 15 | total_timesteps 3000.
Path 16 | total_timesteps 3200.
Path 17 | total_timesteps 3400.
Path 18 | total_timesteps 3600.
Path 19 | total_timesteps 3800.
Path 20 | total_timesteps 4000.
Path 21 | total_timesteps 4200.
Path 22 | total_timesteps 4400.
Path 23 | total_timesteps 4600.
Path 24 | total_timesteps 4800.
Done generating on-policy rollouts.
Updating normalization.
Done updating normalization.
----------------------------
| AverageReturn | 168      |
| Iteration     | 31       |
| MaximumReturn | 199      |
| MinimumReturn | 132      |
| TotalSamples  | 109989   |
----------------------------
itr #32 | 
Fitting dynamics.
Fitting model 0 (0-based) in the ensemble of 5 models
Validation loss = 0.0005622244789265096
Validation loss = 0.0006111442926339805
Validation loss = 0.000584889785386622
Validation loss = 0.0005985436146147549
Validation loss = 0.000596140802372247
Fitting model 1 (0-based) in the ensemble of 5 models
Validation loss = 0.0005377625930123031
Validation loss = 0.0006210037390701473
Validation loss = 0.0005438649677671492
Validation loss = 0.0005533522926270962
Validation loss = 0.0005574563983827829
Fitting model 2 (0-based) in the ensemble of 5 models
Validation loss = 0.00052530417451635
Validation loss = 0.0005308208637870848
Validation loss = 0.0005654745036736131
Validation loss = 0.0006528920494019985
Validation loss = 0.0005679781315848231
Fitting model 3 (0-based) in the ensemble of 5 models
Validation loss = 0.0005312100984156132
Validation loss = 0.0005193866090849042
Validation loss = 0.0005463267443701625
Validation loss = 0.0006073052645660937
Validation loss = 0.0005553131341002882
Validation loss = 0.000609232229180634
Fitting model 4 (0-based) in the ensemble of 5 models
Validation loss = 0.0005410092999227345
Validation loss = 0.0004970443551428616
Validation loss = 0.0005291208508424461
Validation loss = 0.0005287128151394427
Validation loss = 0.0005152019439265132
Validation loss = 0.0005588693311437964
Done fitting dynamics.
Updating randomness.
Done updating randomness.
Training policy using TRPO.
Re-initialize init_std.
Obtaining samples for iteration 0...
Obtaining samples for iteration 1...
Obtaining samples for iteration 2...
Obtaining samples for iteration 3...
Obtaining samples for iteration 4...
Obtaining samples for iteration 5...
Obtaining samples for iteration 6...
Obtaining samples for iteration 7...
Obtaining samples for iteration 8...
Obtaining samples for iteration 9...
Obtaining samples for iteration 10...
Obtaining samples for iteration 11...
Obtaining samples for iteration 12...
Obtaining samples for iteration 13...
Obtaining samples for iteration 14...
Obtaining samples for iteration 15...
Obtaining samples for iteration 16...
Obtaining samples for iteration 17...
Obtaining samples for iteration 18...
Obtaining samples for iteration 19...
Done training policy.
Generating on-policy rollouts.
Path 0 | total_timesteps 0.
Path 1 | total_timesteps 200.
Path 2 | total_timesteps 400.
Path 3 | total_timesteps 600.
Path 4 | total_timesteps 800.
Path 5 | total_timesteps 1000.
Path 6 | total_timesteps 1200.
Path 7 | total_timesteps 1400.
Path 8 | total_timesteps 1600.
Path 9 | total_timesteps 1800.
Path 10 | total_timesteps 2000.
Path 11 | total_timesteps 2200.
Path 12 | total_timesteps 2400.
Path 13 | total_timesteps 2600.
Path 14 | total_timesteps 2800.
Path 15 | total_timesteps 3000.
Path 16 | total_timesteps 3200.
Path 17 | total_timesteps 3400.
Path 18 | total_timesteps 3600.
Path 19 | total_timesteps 3800.
Path 20 | total_timesteps 4000.
Path 21 | total_timesteps 4200.
Path 22 | total_timesteps 4400.
Path 23 | total_timesteps 4600.
Path 24 | total_timesteps 4800.
Done generating on-policy rollouts.
Updating normalization.
Done updating normalization.
----------------------------
| AverageReturn | 174      |
| Iteration     | 32       |
| MaximumReturn | 199      |
| MinimumReturn | 118      |
| TotalSamples  | 113322   |
----------------------------
itr #33 | 
Fitting dynamics.
Fitting model 0 (0-based) in the ensemble of 5 models
Validation loss = 0.0006477952701970935
Validation loss = 0.0006228922284208238
Validation loss = 0.000625037238933146
Validation loss = 0.00047691763029433787
Validation loss = 0.0005620807642117143
Validation loss = 0.000594593002460897
Validation loss = 0.0006203531520441175
Validation loss = 0.0005009759333916008
Fitting model 1 (0-based) in the ensemble of 5 models
Validation loss = 0.0005870607565157115
Validation loss = 0.0005442870897240937
Validation loss = 0.0005828725988976657
Validation loss = 0.0006070637027733028
Validation loss = 0.000543491099961102
Validation loss = 0.0004942067316733301
Validation loss = 0.0005796904442831874
Validation loss = 0.0007087851990945637
Validation loss = 0.0005142843001522124
Validation loss = 0.0005877196090295911
Fitting model 2 (0-based) in the ensemble of 5 models
Validation loss = 0.0006027602357789874
Validation loss = 0.0005130065837875009
Validation loss = 0.0005560896242968738
Validation loss = 0.0005303850630298257
Validation loss = 0.0005579278222285211
Validation loss = 0.0005208156071603298
Fitting model 3 (0-based) in the ensemble of 5 models
Validation loss = 0.0005886232829652727
Validation loss = 0.0005475928192026913
Validation loss = 0.0005404451512731612
Validation loss = 0.0006797820096835494
Validation loss = 0.0004962670500390232
Validation loss = 0.0005661822506226599
Validation loss = 0.000594946148339659
Validation loss = 0.0005373568856157362
Validation loss = 0.0005803384119644761
Fitting model 4 (0-based) in the ensemble of 5 models
Validation loss = 0.0005917760427109897
Validation loss = 0.0005365820834413171
Validation loss = 0.0005253146518953145
Validation loss = 0.0005365699180401862
Validation loss = 0.0005624801269732416
Validation loss = 0.0005482104606926441
Validation loss = 0.000575068814214319
Done fitting dynamics.
Updating randomness.
Done updating randomness.
Training policy using TRPO.
Re-initialize init_std.
Obtaining samples for iteration 0...
Obtaining samples for iteration 1...
Obtaining samples for iteration 2...
Obtaining samples for iteration 3...
Obtaining samples for iteration 4...
Obtaining samples for iteration 5...
Obtaining samples for iteration 6...
Obtaining samples for iteration 7...
Obtaining samples for iteration 8...
Obtaining samples for iteration 9...
Obtaining samples for iteration 10...
Obtaining samples for iteration 11...
Obtaining samples for iteration 12...
Obtaining samples for iteration 13...
Obtaining samples for iteration 14...
Obtaining samples for iteration 15...
Obtaining samples for iteration 16...
Obtaining samples for iteration 17...
Obtaining samples for iteration 18...
Obtaining samples for iteration 19...
Done training policy.
Generating on-policy rollouts.
Path 0 | total_timesteps 0.
Path 1 | total_timesteps 200.
Path 2 | total_timesteps 400.
Path 3 | total_timesteps 600.
Path 4 | total_timesteps 800.
Path 5 | total_timesteps 1000.
Path 6 | total_timesteps 1200.
Path 7 | total_timesteps 1400.
Path 8 | total_timesteps 1600.
Path 9 | total_timesteps 1800.
Path 10 | total_timesteps 2000.
Path 11 | total_timesteps 2200.
Path 12 | total_timesteps 2400.
Path 13 | total_timesteps 2600.
Path 14 | total_timesteps 2800.
Path 15 | total_timesteps 3000.
Path 16 | total_timesteps 3200.
Path 17 | total_timesteps 3400.
Path 18 | total_timesteps 3600.
Path 19 | total_timesteps 3800.
Path 20 | total_timesteps 4000.
Path 21 | total_timesteps 4200.
Path 22 | total_timesteps 4400.
Path 23 | total_timesteps 4600.
Path 24 | total_timesteps 4800.
Done generating on-policy rollouts.
Updating normalization.
Done updating normalization.
----------------------------
| AverageReturn | 162      |
| Iteration     | 33       |
| MaximumReturn | 199      |
| MinimumReturn | 109      |
| TotalSamples  | 116655   |
----------------------------
itr #34 | 
Fitting dynamics.
Fitting model 0 (0-based) in the ensemble of 5 models
Validation loss = 0.0007204465218819678
Validation loss = 0.0006679326761513948
Validation loss = 0.000508285069372505
Validation loss = 0.0005132684018462896
Validation loss = 0.0005153145757503808
Validation loss = 0.0005159612628631294
Validation loss = 0.0005625960766337812
Fitting model 1 (0-based) in the ensemble of 5 models
Validation loss = 0.0004964763065800071
Validation loss = 0.0005235859425738454
Validation loss = 0.0006530345999635756
Validation loss = 0.0005822543753311038
Validation loss = 0.0005905083962716162
Fitting model 2 (0-based) in the ensemble of 5 models
Validation loss = 0.0005296909948810935
Validation loss = 0.0004968614084646106
Validation loss = 0.0005871955654583871
Validation loss = 0.0005153906531631947
Validation loss = 0.0005262174527160823
Validation loss = 0.0005372494924813509
Fitting model 3 (0-based) in the ensemble of 5 models
Validation loss = 0.0005437946529127657
Validation loss = 0.0005194009863771498
Validation loss = 0.0006888757925480604
Validation loss = 0.0006115207215771079
Validation loss = 0.0005994662642478943
Validation loss = 0.0006342460983432829
Fitting model 4 (0-based) in the ensemble of 5 models
Validation loss = 0.0005319849005900323
Validation loss = 0.0007963631651364267
Validation loss = 0.000568009854760021
Validation loss = 0.0005356735782697797
Validation loss = 0.0004966083215549588
Validation loss = 0.0006051893578842282
Validation loss = 0.0006050941301509738
Validation loss = 0.0005554058006964624
Validation loss = 0.0004966289270669222
Done fitting dynamics.
Updating randomness.
Done updating randomness.
Training policy using TRPO.
Re-initialize init_std.
Obtaining samples for iteration 0...
Obtaining samples for iteration 1...
Obtaining samples for iteration 2...
Obtaining samples for iteration 3...
Obtaining samples for iteration 4...
Obtaining samples for iteration 5...
Obtaining samples for iteration 6...
Obtaining samples for iteration 7...
Obtaining samples for iteration 8...
Obtaining samples for iteration 9...
Obtaining samples for iteration 10...
Obtaining samples for iteration 11...
Obtaining samples for iteration 12...
Obtaining samples for iteration 13...
Obtaining samples for iteration 14...
Obtaining samples for iteration 15...
Obtaining samples for iteration 16...
Obtaining samples for iteration 17...
Obtaining samples for iteration 18...
Obtaining samples for iteration 19...
Done training policy.
Generating on-policy rollouts.
Path 0 | total_timesteps 0.
Path 1 | total_timesteps 200.
Path 2 | total_timesteps 400.
Path 3 | total_timesteps 600.
Path 4 | total_timesteps 800.
Path 5 | total_timesteps 1000.
Path 6 | total_timesteps 1200.
Path 7 | total_timesteps 1400.
Path 8 | total_timesteps 1600.
Path 9 | total_timesteps 1800.
Path 10 | total_timesteps 2000.
Path 11 | total_timesteps 2200.
Path 12 | total_timesteps 2400.
Path 13 | total_timesteps 2600.
Path 14 | total_timesteps 2800.
Path 15 | total_timesteps 3000.
Path 16 | total_timesteps 3200.
Path 17 | total_timesteps 3400.
Path 18 | total_timesteps 3600.
Path 19 | total_timesteps 3800.
Path 20 | total_timesteps 4000.
Path 21 | total_timesteps 4200.
Path 22 | total_timesteps 4400.
Path 23 | total_timesteps 4600.
Path 24 | total_timesteps 4800.
Done generating on-policy rollouts.
Updating normalization.
Done updating normalization.
----------------------------
| AverageReturn | 175      |
| Iteration     | 34       |
| MaximumReturn | 199      |
| MinimumReturn | 128      |
| TotalSamples  | 119988   |
----------------------------
itr #35 | 
Fitting dynamics.
Fitting model 0 (0-based) in the ensemble of 5 models
Validation loss = 0.0005767839611507952
Validation loss = 0.0005566886393353343
Validation loss = 0.0007903053192421794
Validation loss = 0.0006938618025742471
Validation loss = 0.0005991783109493554
Validation loss = 0.0004889116389676929
Validation loss = 0.0005344178644008934
Validation loss = 0.0005791523726657033
Validation loss = 0.0005913456552661955
Validation loss = 0.0005511986673809588
Fitting model 1 (0-based) in the ensemble of 5 models
Validation loss = 0.0006033783429302275
Validation loss = 0.0005109002813696861
Validation loss = 0.000540109642315656
Validation loss = 0.0005776528269052505
Validation loss = 0.000542628054972738
Validation loss = 0.0005039914394728839
Validation loss = 0.0005118681583553553
Validation loss = 0.0005557450349442661
Validation loss = 0.0005181410233490169
Validation loss = 0.0004906230024062097
Validation loss = 0.00052677869098261
Validation loss = 0.0005224021733738482
Validation loss = 0.0006194347515702248
Validation loss = 0.0005001226090826094
Fitting model 2 (0-based) in the ensemble of 5 models
Validation loss = 0.0006222940282896161
Validation loss = 0.000516245374456048
Validation loss = 0.0006488783983513713
Validation loss = 0.0005356197361834347
Validation loss = 0.0005535414675250649
Validation loss = 0.0005352540756575763
Fitting model 3 (0-based) in the ensemble of 5 models
Validation loss = 0.0005338965565897524
Validation loss = 0.0005826567066833377
Validation loss = 0.0005202354514040053
Validation loss = 0.000580651976633817
Validation loss = 0.0005589572829194367
Validation loss = 0.00055868731578812
Validation loss = 0.0006230648141354322
Fitting model 4 (0-based) in the ensemble of 5 models
Validation loss = 0.0005025680875405669
Validation loss = 0.0005743092624470592
Validation loss = 0.0006958636804483831
Validation loss = 0.000520880741532892
Validation loss = 0.000540266977623105
Done fitting dynamics.
Updating randomness.
Done updating randomness.
Training policy using TRPO.
Re-initialize init_std.
Obtaining samples for iteration 0...
Obtaining samples for iteration 1...
Obtaining samples for iteration 2...
Obtaining samples for iteration 3...
Obtaining samples for iteration 4...
Obtaining samples for iteration 5...
Obtaining samples for iteration 6...
Obtaining samples for iteration 7...
Obtaining samples for iteration 8...
Obtaining samples for iteration 9...
Obtaining samples for iteration 10...
Obtaining samples for iteration 11...
Obtaining samples for iteration 12...
Obtaining samples for iteration 13...
Obtaining samples for iteration 14...
Obtaining samples for iteration 15...
Obtaining samples for iteration 16...
Obtaining samples for iteration 17...
Obtaining samples for iteration 18...
Obtaining samples for iteration 19...
Done training policy.
Generating on-policy rollouts.
Path 0 | total_timesteps 0.
Path 1 | total_timesteps 200.
Path 2 | total_timesteps 400.
Path 3 | total_timesteps 600.
Path 4 | total_timesteps 800.
Path 5 | total_timesteps 1000.
Path 6 | total_timesteps 1200.
Path 7 | total_timesteps 1400.
Path 8 | total_timesteps 1600.
Path 9 | total_timesteps 1800.
Path 10 | total_timesteps 2000.
Path 11 | total_timesteps 2200.
Path 12 | total_timesteps 2400.
Path 13 | total_timesteps 2600.
Path 14 | total_timesteps 2800.
Path 15 | total_timesteps 3000.
Path 16 | total_timesteps 3200.
Path 17 | total_timesteps 3400.
Path 18 | total_timesteps 3600.
Path 19 | total_timesteps 3800.
Path 20 | total_timesteps 4000.
Path 21 | total_timesteps 4200.
Path 22 | total_timesteps 4400.
Path 23 | total_timesteps 4600.
Path 24 | total_timesteps 4800.
Done generating on-policy rollouts.
Updating normalization.
Done updating normalization.
----------------------------
| AverageReturn | 186      |
| Iteration     | 35       |
| MaximumReturn | 199      |
| MinimumReturn | 127      |
| TotalSamples  | 123321   |
----------------------------
itr #36 | 
Fitting dynamics.
Fitting model 0 (0-based) in the ensemble of 5 models
Validation loss = 0.0005857225623913109
Validation loss = 0.0006416654214262962
Validation loss = 0.0005283140926621854
Validation loss = 0.0004882646317128092
Validation loss = 0.0006340655381791294
Validation loss = 0.0005279902252368629
Validation loss = 0.0005465905414894223
Validation loss = 0.0005855714553035796
Fitting model 1 (0-based) in the ensemble of 5 models
Validation loss = 0.0005174581310711801
Validation loss = 0.0007382592302747071
Validation loss = 0.0005331445136107504
Validation loss = 0.0005252078408375382
Validation loss = 0.0005852676113136113
Fitting model 2 (0-based) in the ensemble of 5 models
Validation loss = 0.0005220068851485848
Validation loss = 0.0005576061666943133
Validation loss = 0.0005599281284958124
Validation loss = 0.0006333788624033332
Validation loss = 0.0004902063519693911
Validation loss = 0.0006272431346587837
Validation loss = 0.0005190201918594539
Validation loss = 0.0005263700149953365
Validation loss = 0.00048003639676608145
Validation loss = 0.0005565622705034912
Validation loss = 0.0005272846319712698
Validation loss = 0.0005396410706453025
Validation loss = 0.0005959747941233218
Fitting model 3 (0-based) in the ensemble of 5 models
Validation loss = 0.0005210796953178942
Validation loss = 0.000867233844473958
Validation loss = 0.0005159119027666748
Validation loss = 0.0005089390906505287
Validation loss = 0.0004915354074910283
Validation loss = 0.000557393825147301
Validation loss = 0.0005206335918046534
Validation loss = 0.0005524711450561881
Validation loss = 0.0005188407958485186
Fitting model 4 (0-based) in the ensemble of 5 models
Validation loss = 0.0004893299774266779
Validation loss = 0.0005964439478702843
Validation loss = 0.0006014332757331431
Validation loss = 0.0005053880158811808
Validation loss = 0.000582673994358629
Done fitting dynamics.
Updating randomness.
Done updating randomness.
Training policy using TRPO.
Re-initialize init_std.
Obtaining samples for iteration 0...
Obtaining samples for iteration 1...
Obtaining samples for iteration 2...
Obtaining samples for iteration 3...
Obtaining samples for iteration 4...
Obtaining samples for iteration 5...
Obtaining samples for iteration 6...
Obtaining samples for iteration 7...
Obtaining samples for iteration 8...
Obtaining samples for iteration 9...
Obtaining samples for iteration 10...
Obtaining samples for iteration 11...
Obtaining samples for iteration 12...
Obtaining samples for iteration 13...
Obtaining samples for iteration 14...
Obtaining samples for iteration 15...
Obtaining samples for iteration 16...
Obtaining samples for iteration 17...
Obtaining samples for iteration 18...
Obtaining samples for iteration 19...
Done training policy.
Generating on-policy rollouts.
Path 0 | total_timesteps 0.
Path 1 | total_timesteps 200.
Path 2 | total_timesteps 400.
Path 3 | total_timesteps 600.
Path 4 | total_timesteps 800.
Path 5 | total_timesteps 1000.
Path 6 | total_timesteps 1200.
Path 7 | total_timesteps 1400.
Path 8 | total_timesteps 1600.
Path 9 | total_timesteps 1800.
Path 10 | total_timesteps 2000.
Path 11 | total_timesteps 2200.
Path 12 | total_timesteps 2400.
Path 13 | total_timesteps 2600.
Path 14 | total_timesteps 2800.
Path 15 | total_timesteps 3000.
Path 16 | total_timesteps 3200.
Path 17 | total_timesteps 3400.
Path 18 | total_timesteps 3600.
Path 19 | total_timesteps 3800.
Path 20 | total_timesteps 4000.
Path 21 | total_timesteps 4200.
Path 22 | total_timesteps 4400.
Path 23 | total_timesteps 4600.
Path 24 | total_timesteps 4800.
Done generating on-policy rollouts.
Updating normalization.
Done updating normalization.
----------------------------
| AverageReturn | 175      |
| Iteration     | 36       |
| MaximumReturn | 199      |
| MinimumReturn | 118      |
| TotalSamples  | 126654   |
----------------------------
itr #37 | 
Fitting dynamics.
Fitting model 0 (0-based) in the ensemble of 5 models
Validation loss = 0.0004886300303041935
Validation loss = 0.0004896302125416696
Validation loss = 0.0005644359043799341
Validation loss = 0.0005013059126213193
Validation loss = 0.0005220863386057317
Fitting model 1 (0-based) in the ensemble of 5 models
Validation loss = 0.0006702918326482177
Validation loss = 0.000650440517347306
Validation loss = 0.0005137696862220764
Validation loss = 0.0006454440299421549
Validation loss = 0.0005827649147249758
Validation loss = 0.0005880632088519633
Validation loss = 0.0005022521945647895
Validation loss = 0.0005151689983904362
Validation loss = 0.0005912730121053755
Validation loss = 0.0005593536188825965
Validation loss = 0.0005151949007995427
Fitting model 2 (0-based) in the ensemble of 5 models
Validation loss = 0.0005192920798435807
Validation loss = 0.0004955069744028151
Validation loss = 0.0005738678155466914
Validation loss = 0.0005121007561683655
Validation loss = 0.0004988803993910551
Validation loss = 0.0005218901205807924
Fitting model 3 (0-based) in the ensemble of 5 models
Validation loss = 0.000521134352311492
Validation loss = 0.0005236266879364848
Validation loss = 0.0004935519536957145
Validation loss = 0.0005136602558195591
Validation loss = 0.0005316160386428237
Validation loss = 0.0006207028636708856
Validation loss = 0.0004836847074329853
Validation loss = 0.0007315063267014921
Validation loss = 0.0005461275577545166
Validation loss = 0.0005131879588589072
Validation loss = 0.0006595710292458534
Fitting model 4 (0-based) in the ensemble of 5 models
Validation loss = 0.000619139987975359
Validation loss = 0.000591920455917716
Validation loss = 0.0005298707401379943
Validation loss = 0.0005579511635005474
Validation loss = 0.0005226207431405783
Validation loss = 0.0004836894222535193
Validation loss = 0.000530934426933527
Validation loss = 0.0005808149580843747
Validation loss = 0.0005143345915712416
Validation loss = 0.0005192951066419482
Done fitting dynamics.
Updating randomness.
Done updating randomness.
Training policy using TRPO.
Re-initialize init_std.
Obtaining samples for iteration 0...
Obtaining samples for iteration 1...
Obtaining samples for iteration 2...
Obtaining samples for iteration 3...
Obtaining samples for iteration 4...
Obtaining samples for iteration 5...
Obtaining samples for iteration 6...
Obtaining samples for iteration 7...
Obtaining samples for iteration 8...
Obtaining samples for iteration 9...
Obtaining samples for iteration 10...
Obtaining samples for iteration 11...
Obtaining samples for iteration 12...
Obtaining samples for iteration 13...
Obtaining samples for iteration 14...
Obtaining samples for iteration 15...
Obtaining samples for iteration 16...
Obtaining samples for iteration 17...
Obtaining samples for iteration 18...
Obtaining samples for iteration 19...
Done training policy.
Generating on-policy rollouts.
Path 0 | total_timesteps 0.
Path 1 | total_timesteps 200.
Path 2 | total_timesteps 400.
Path 3 | total_timesteps 600.
Path 4 | total_timesteps 800.
Path 5 | total_timesteps 1000.
Path 6 | total_timesteps 1200.
Path 7 | total_timesteps 1400.
Path 8 | total_timesteps 1600.
Path 9 | total_timesteps 1800.
Path 10 | total_timesteps 2000.
Path 11 | total_timesteps 2200.
Path 12 | total_timesteps 2400.
Path 13 | total_timesteps 2600.
Path 14 | total_timesteps 2800.
Path 15 | total_timesteps 3000.
Path 16 | total_timesteps 3200.
Path 17 | total_timesteps 3400.
Path 18 | total_timesteps 3600.
Path 19 | total_timesteps 3800.
Path 20 | total_timesteps 4000.
Path 21 | total_timesteps 4200.
Path 22 | total_timesteps 4400.
Path 23 | total_timesteps 4600.
Path 24 | total_timesteps 4800.
Done generating on-policy rollouts.
Updating normalization.
Done updating normalization.
----------------------------
| AverageReturn | 172      |
| Iteration     | 37       |
| MaximumReturn | 199      |
| MinimumReturn | 131      |
| TotalSamples  | 129987   |
----------------------------
itr #38 | 
Fitting dynamics.
Fitting model 0 (0-based) in the ensemble of 5 models
Validation loss = 0.0006366471643559635
Validation loss = 0.0006096289143897593
Validation loss = 0.000514919520355761
Validation loss = 0.0005931985797360539
Validation loss = 0.0005430684541352093
Validation loss = 0.0014645218616351485
Validation loss = 0.0005756043246947229
Fitting model 1 (0-based) in the ensemble of 5 models
Validation loss = 0.0005550156929530203
Validation loss = 0.0005214600241743028
Validation loss = 0.0005716070882044733
Validation loss = 0.0006051533855497837
Validation loss = 0.0004962726379744709
Validation loss = 0.0005287441308610141
Validation loss = 0.0004720178840216249
Validation loss = 0.0006205816171132028
Validation loss = 0.0005277651362121105
Validation loss = 0.000500375812407583
Validation loss = 0.00048360726214013994
Fitting model 2 (0-based) in the ensemble of 5 models
Validation loss = 0.0005488179158419371
Validation loss = 0.0005947513272985816
Validation loss = 0.0005136154359206557
Validation loss = 0.0004958838107995689
Validation loss = 0.000572195858694613
Validation loss = 0.000559335807338357
Validation loss = 0.0004989507724530995
Validation loss = 0.0005421395762823522
Fitting model 3 (0-based) in the ensemble of 5 models
Validation loss = 0.0005014555063098669
Validation loss = 0.0005633803084492683
Validation loss = 0.0005457296501845121
Validation loss = 0.000532221223693341
Validation loss = 0.0005261530168354511
Fitting model 4 (0-based) in the ensemble of 5 models
Validation loss = 0.0005713252467103302
Validation loss = 0.0007183505804277956
Validation loss = 0.0005352075095288455
Validation loss = 0.0005797978374175727
Validation loss = 0.0004758596478495747
Validation loss = 0.0005199654842726886
Validation loss = 0.0006019151769578457
Validation loss = 0.0005492939963005483
Validation loss = 0.000529700715560466
Done fitting dynamics.
Updating randomness.
Done updating randomness.
Training policy using TRPO.
Re-initialize init_std.
Obtaining samples for iteration 0...
Obtaining samples for iteration 1...
Obtaining samples for iteration 2...
Obtaining samples for iteration 3...
Obtaining samples for iteration 4...
Obtaining samples for iteration 5...
Obtaining samples for iteration 6...
Obtaining samples for iteration 7...
Obtaining samples for iteration 8...
Obtaining samples for iteration 9...
Obtaining samples for iteration 10...
Obtaining samples for iteration 11...
Obtaining samples for iteration 12...
Obtaining samples for iteration 13...
Obtaining samples for iteration 14...
Obtaining samples for iteration 15...
Obtaining samples for iteration 16...
Obtaining samples for iteration 17...
Obtaining samples for iteration 18...
Obtaining samples for iteration 19...
Done training policy.
Generating on-policy rollouts.
Path 0 | total_timesteps 0.
Path 1 | total_timesteps 200.
Path 2 | total_timesteps 400.
Path 3 | total_timesteps 600.
Path 4 | total_timesteps 800.
Path 5 | total_timesteps 1000.
Path 6 | total_timesteps 1200.
Path 7 | total_timesteps 1400.
Path 8 | total_timesteps 1600.
Path 9 | total_timesteps 1800.
Path 10 | total_timesteps 2000.
Path 11 | total_timesteps 2200.
Path 12 | total_timesteps 2400.
Path 13 | total_timesteps 2600.
Path 14 | total_timesteps 2800.
Path 15 | total_timesteps 3000.
Path 16 | total_timesteps 3200.
Path 17 | total_timesteps 3400.
Path 18 | total_timesteps 3600.
Path 19 | total_timesteps 3800.
Path 20 | total_timesteps 4000.
Path 21 | total_timesteps 4200.
Path 22 | total_timesteps 4400.
Path 23 | total_timesteps 4600.
Path 24 | total_timesteps 4800.
Done generating on-policy rollouts.
Updating normalization.
Done updating normalization.
----------------------------
| AverageReturn | 172      |
| Iteration     | 38       |
| MaximumReturn | 199      |
| MinimumReturn | 123      |
| TotalSamples  | 133320   |
----------------------------
itr #39 | 
Fitting dynamics.
Fitting model 0 (0-based) in the ensemble of 5 models
Validation loss = 0.0005078385584056377
Validation loss = 0.0005381516530178487
Validation loss = 0.0005236220313236117
Validation loss = 0.0005598837742581964
Validation loss = 0.0005802527302876115
Fitting model 1 (0-based) in the ensemble of 5 models
Validation loss = 0.0005808502319268882
Validation loss = 0.0005373150925152004
Validation loss = 0.0004959492362104356
Validation loss = 0.0005514905205927789
Validation loss = 0.0005464082933031023
Validation loss = 0.0005487722810357809
Validation loss = 0.000521533889696002
Fitting model 2 (0-based) in the ensemble of 5 models
Validation loss = 0.0006289155571721494
Validation loss = 0.00048122493899427354
Validation loss = 0.00047955085756257176
Validation loss = 0.000540933629963547
Validation loss = 0.0005341313080862164
Validation loss = 0.0006497767753899097
Validation loss = 0.0005339158815331757
Fitting model 3 (0-based) in the ensemble of 5 models
Validation loss = 0.0005836103809997439
Validation loss = 0.0004943156382068992
Validation loss = 0.0005241489852778614
Validation loss = 0.0005378075293265283
Validation loss = 0.0004966351552866399
Validation loss = 0.0005902342381887138
Fitting model 4 (0-based) in the ensemble of 5 models
Validation loss = 0.0005037087248638272
Validation loss = 0.0005663676420226693
Validation loss = 0.0005326283280737698
Validation loss = 0.0005175388650968671
Validation loss = 0.00050436204764992
Done fitting dynamics.
Updating randomness.
Done updating randomness.
Training policy using TRPO.
Re-initialize init_std.
Obtaining samples for iteration 0...
Obtaining samples for iteration 1...
Obtaining samples for iteration 2...
Obtaining samples for iteration 3...
Obtaining samples for iteration 4...
Obtaining samples for iteration 5...
Obtaining samples for iteration 6...
Obtaining samples for iteration 7...
Obtaining samples for iteration 8...
Obtaining samples for iteration 9...
Obtaining samples for iteration 10...
Obtaining samples for iteration 11...
Obtaining samples for iteration 12...
Obtaining samples for iteration 13...
Obtaining samples for iteration 14...
Obtaining samples for iteration 15...
Obtaining samples for iteration 16...
Obtaining samples for iteration 17...
Obtaining samples for iteration 18...
Obtaining samples for iteration 19...
Done training policy.
Generating on-policy rollouts.
Path 0 | total_timesteps 0.
Path 1 | total_timesteps 200.
Path 2 | total_timesteps 400.
Path 3 | total_timesteps 600.
Path 4 | total_timesteps 800.
Path 5 | total_timesteps 1000.
Path 6 | total_timesteps 1200.
Path 7 | total_timesteps 1400.
Path 8 | total_timesteps 1600.
Path 9 | total_timesteps 1800.
Path 10 | total_timesteps 2000.
Path 11 | total_timesteps 2200.
Path 12 | total_timesteps 2400.
Path 13 | total_timesteps 2600.
Path 14 | total_timesteps 2800.
Path 15 | total_timesteps 3000.
Path 16 | total_timesteps 3200.
Path 17 | total_timesteps 3400.
Path 18 | total_timesteps 3600.
Path 19 | total_timesteps 3800.
Path 20 | total_timesteps 4000.
Path 21 | total_timesteps 4200.
Path 22 | total_timesteps 4400.
Path 23 | total_timesteps 4600.
Path 24 | total_timesteps 4800.
Done generating on-policy rollouts.
Updating normalization.
Done updating normalization.
----------------------------
| AverageReturn | 167      |
| Iteration     | 39       |
| MaximumReturn | 199      |
| MinimumReturn | 121      |
| TotalSamples  | 136653   |
----------------------------
